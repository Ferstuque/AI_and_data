{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTK5gY8gtZ0sODUrGKEd2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b975953b3ac44439b14592fb93ce1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8e00dc9a7734527821244f6b248dfce",
              "IPY_MODEL_88ab70fc63104b9fbf2f49638b8f62a5",
              "IPY_MODEL_8a660597753444908970e55988eb2539"
            ],
            "layout": "IPY_MODEL_a747abb624b94c89aa363a632d10747f"
          }
        },
        "c8e00dc9a7734527821244f6b248dfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a0177277584442ab57d096b8d1c683",
            "placeholder": "​",
            "style": "IPY_MODEL_43a9fb5c50194b389b261742e7c7a5a5",
            "value": "Map: 100%"
          }
        },
        "88ab70fc63104b9fbf2f49638b8f62a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e900c6725a4acaba0d38943bf8d695",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60d6116253ab436d89960f046e049c19",
            "value": 3000
          }
        },
        "8a660597753444908970e55988eb2539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fea0c2448ae4a84a3aae59edb668e05",
            "placeholder": "​",
            "style": "IPY_MODEL_04c48443509f4f9da5cc8df0286d57c1",
            "value": " 3000/3000 [00:00&lt;00:00, 12747.92 examples/s]"
          }
        },
        "a747abb624b94c89aa363a632d10747f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a0177277584442ab57d096b8d1c683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a9fb5c50194b389b261742e7c7a5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e900c6725a4acaba0d38943bf8d695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d6116253ab436d89960f046e049c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fea0c2448ae4a84a3aae59edb668e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c48443509f4f9da5cc8df0286d57c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36aa6d2ac3ed4160a1382ba850bd55c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffbf064e87ce4e2e9327ab673339fd07",
              "IPY_MODEL_ac86385d15ee4b17b1a7ff3347a00e58",
              "IPY_MODEL_b4c9cf093c8141a1b3fd766284cd3344"
            ],
            "layout": "IPY_MODEL_6dddf0c87b7941308ac6d24ca540a953"
          }
        },
        "ffbf064e87ce4e2e9327ab673339fd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b60949fe3dd641489f36f8c1ff35faf8",
            "placeholder": "​",
            "style": "IPY_MODEL_4392f4187cbd496bb96f9fb0b3bd55ca",
            "value": "Map: 100%"
          }
        },
        "ac86385d15ee4b17b1a7ff3347a00e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc275d328244e70981e2877817ca4a9",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fbf02a169274006b29f1d61d5a23130",
            "value": 3000
          }
        },
        "b4c9cf093c8141a1b3fd766284cd3344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d04a4a8fa794654937c5cb8f03aac04",
            "placeholder": "​",
            "style": "IPY_MODEL_34af15605cef41d4aaa0c79bfb266862",
            "value": " 3000/3000 [00:03&lt;00:00, 772.88 examples/s]"
          }
        },
        "6dddf0c87b7941308ac6d24ca540a953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60949fe3dd641489f36f8c1ff35faf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4392f4187cbd496bb96f9fb0b3bd55ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc275d328244e70981e2877817ca4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbf02a169274006b29f1d61d5a23130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d04a4a8fa794654937c5cb8f03aac04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34af15605cef41d4aaa0c79bfb266862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ferstuque/AI_and_data/blob/main/LLM_GPT2_Fine_Tuning_HuggingFace_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook - Fine-tuning do GPT2-Small para Geração de Texto com Dataset da Hugging Face\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8BECthl934nx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook apresenta um exemplo prático de como integrar um modelo de linguagem grande GPT-2 Small pré-treinado e um dataset, ambos fornecidos pelo Hugging Face. O conteúdo está dividido em três etapas, que incluem uma análise detalhada e potenciais otimizações para o modelo de geração de texto."
      ],
      "metadata": {
        "id": "IgQzUCmkGA8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📣 É altamente recomendado que utilize um cluster de GPU do Google Colab para performar este notebook."
      ],
      "metadata": {
        "id": "eBYyLoGeTH6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate evaluate bert-score nltk\n",
        "!pip install git-lfs"
      ],
      "metadata": {
        "id": "u_vCoNjPVGKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando se o GPU NVIDIA está habilitado\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9SwoKCbekrgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚙️ Instalando dependencias"
      ],
      "metadata": {
        "id": "CmuYhWtzbFY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from transformers import (pipeline,\n",
        "                          set_seed,\n",
        "                          AutoTokenizer,\n",
        "                          GPT2LMHeadModel,\n",
        "                          GPT2Tokenizer,\n",
        "                          GPT2Config,\n",
        "                          GPT2ForSequenceClassification,\n",
        "                          TrainingArguments,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          Trainer,\n",
        "                          get_linear_schedule_with_warmup,\n",
        "                          AutoModelForCausalLM)\n",
        "from google.colab import userdata\n",
        "import evaluate\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "torch.manual_seed(456)\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "j7JtpzhqZ9yz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 1"
      ],
      "metadata": {
        "id": "Mv8d_Jbs5dVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão dos Datasets\n",
        "\n",
        "* Dataset de treino: 3000 linhas (escolha aleatória)\n",
        "* Dataset de teste: 3000 linhas (escolha aleatória)"
      ],
      "metadata": {
        "id": "8WOjg-eCUCg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "--2Up4AVUcAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  dataset_train = load_dataset(\"tatsu-lab/alpaca\", split=\"train[:3000]\").remove_columns(['text'])\n",
        "  dataset_test = load_dataset(\"tatsu-lab/alpaca\", split=\"train[-3000:]\").remove_columns(['text'])\n",
        "  print(f'Train:\\n{dataset_train}')\n",
        "  print(f'Test:\\n{dataset_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xr8A4a3VUr1",
        "outputId": "506c54d0-ceed-461d-d90c-680b871dc348"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output'],\n",
            "    num_rows: 3000\n",
            "})\n",
            "Test:\n",
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output'],\n",
            "    num_rows: 3000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_test[0]['instruction'])\n",
        "print(dataset_test[0]['input'])\n",
        "print(dataset_test[0]['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8Z1q4f4Oyk",
        "outputId": "5c8d729f-194d-4b8d-ae9f-b6d275b8bad4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Construct a story given a specific theme of choice.\n",
            "Theme: Friendship\n",
            "Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do modelo com frase aleatória\n",
        "generator = pipeline('text-generation', model='ComCom/gpt2-small', truncation=True)\n",
        "set_seed(456)\n",
        "generator(\"I read epic novel books\", max_length=100, num_return_sequences=1)"
      ],
      "metadata": {
        "id": "koJoYSGN5kOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_gpt2 = pd.DataFrame(dataset_test)\n",
        "df_test_gpt2['generated_text'] = None\n",
        "\n",
        "for index in range(10): # Limitando a apenas 10 linhas de exemplo\n",
        "  instruction = df_test_gpt2.loc[index, 'instruction'] + \" \" + df_test_gpt2.loc[index, 'input']\n",
        "  generated_text = generator(instruction, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
        "  df_test_gpt2.loc[index, 'generated_text'] = generated_text"
      ],
      "metadata": {
        "id": "Beh1i_nn6P2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75c2506-3bf4-4eaa-a771-4a925e7155df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analisando a qualidade do resultado do modelo"
      ],
      "metadata": {
        "id": "6ixzS9-I7VV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "df_test_gpt2.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s0hemclR7UfE",
        "outputId": "6a0c1db7-9c1b-4e20-f159-84c2f9123261"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             instruction  \\\n",
              "0                                    Construct a story given a specific theme of choice.   \n",
              "1                                                Retrieve a fact about a specific topic.   \n",
              "2                   Rearrange a paragraph to make it read in an orderly and logical way.   \n",
              "3                                                    Describe a scene to a blind person.   \n",
              "4                                     Translate a sentence from one language to another.   \n",
              "5                                     Given a scenario, decide which is the best advice.   \n",
              "6                                             Find the difference between 11/80 and 0.13   \n",
              "7                                                       Convert the time from GMT to EST   \n",
              "8  Create a pseudo-code algorithm to find the maximum number in a given list of numbers.   \n",
              "9                  Rewrite this English sentence into Spanish: The sun rises in the east   \n",
              "\n",
              "                                                                                                                                                           input  \\\n",
              "0                                                                                                                                              Theme: Friendship   \n",
              "1                                                                                                                                            Topic: Solar System   \n",
              "2  Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.   \n",
              "3                                                                                                                                 A flower garden in the morning   \n",
              "4                                                                                                         Sentence: Je veux aller à la plage.\\nLanguage: Spanish   \n",
              "5                                                       Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.   \n",
              "6                                                                                                                                                                  \n",
              "7                                                                                                                                                  3:25 p.m. GMT   \n",
              "8                                                                                                                                                                  \n",
              "9                                                                                                                                                                  \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    output  \\\n",
              "0                                                                                                                                         Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                        The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                            Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.   \n",
              "3                                                                                                                                                                               The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Quiero ir a la playa.   \n",
              "5                                                                                                                                                                                                                                                              The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                         The difference between 11/80 and 0.13 is 0.0375.   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                       The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.   \n",
              "8  Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 El sol sale por el este.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                           generated_text  \n",
              "0  Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a  \n",
              "1                                                               Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this  \n",
              "2                          Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing  \n",
              "3                                                       Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister—or both. A night out, the weather improves as it did on Saturday.\\n\\nIt has  \n",
              "4                                                                                                                                                                                                                                                                                                                                            Translate a sentence from one language to another. Sentence: Je veux aller à la plage.\\nLanguage: Spanish - drei\\nLanguage: French - fédérif  \n",
              "5                                                                               Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-  \n",
              "6                                                      Find the difference between 11/80 and 0.13  or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by  \n",
              "7                                                                                                                                                                                     Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard  \n",
              "8                                                                      Create a pseudo-code algorithm to find the maximum number in a given list of numbers.  This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings.  The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%  \n",
              "9                                                     Rewrite this English sentence into Spanish: The sun rises in the east \\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69033958-ba76-4e87-9002-d0d3fba53eb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Construct a story given a specific theme of choice.</td>\n",
              "      <td>Theme: Friendship</td>\n",
              "      <td>Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.</td>\n",
              "      <td>Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Retrieve a fact about a specific topic.</td>\n",
              "      <td>Topic: Solar System</td>\n",
              "      <td>The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.</td>\n",
              "      <td>Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way.</td>\n",
              "      <td>Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.</td>\n",
              "      <td>Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.</td>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Describe a scene to a blind person.</td>\n",
              "      <td>A flower garden in the morning</td>\n",
              "      <td>The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.</td>\n",
              "      <td>Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister—or both. A night out, the weather improves as it did on Saturday.\\n\\nIt has</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Translate a sentence from one language to another.</td>\n",
              "      <td>Sentence: Je veux aller à la plage.\\nLanguage: Spanish</td>\n",
              "      <td>Quiero ir a la playa.</td>\n",
              "      <td>Translate a sentence from one language to another. Sentence: Je veux aller à la plage.\\nLanguage: Spanish - drei\\nLanguage: French - fédérif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Given a scenario, decide which is the best advice.</td>\n",
              "      <td>Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.</td>\n",
              "      <td>The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.</td>\n",
              "      <td>Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Find the difference between 11/80 and 0.13</td>\n",
              "      <td></td>\n",
              "      <td>The difference between 11/80 and 0.13 is 0.0375.</td>\n",
              "      <td>Find the difference between 11/80 and 0.13  or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Convert the time from GMT to EST</td>\n",
              "      <td>3:25 p.m. GMT</td>\n",
              "      <td>The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.</td>\n",
              "      <td>Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers.</td>\n",
              "      <td></td>\n",
              "      <td>Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.</td>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers.  This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings.  The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east</td>\n",
              "      <td></td>\n",
              "      <td>El sol sale por el este.</td>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east \\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69033958-ba76-4e87-9002-d0d3fba53eb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69033958-ba76-4e87-9002-d0d3fba53eb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69033958-ba76-4e87-9002-d0d3fba53eb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c86a98bd-d4a8-4f9d-a7af-7ae06507a8ab\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c86a98bd-d4a8-4f9d-a7af-7ae06507a8ab')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c86a98bd-d4a8-4f9d-a7af-7ae06507a8ab button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_gpt2",
              "summary": "{\n  \"name\": \"df_test_gpt2\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"Answer a trivia question related to this context.\",\n          \"What is a common use case for a machine learning algorithm?\",\n          \"Compare and contrast the characteristics of the desert and the jungle.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1169,\n        \"samples\": [\n          \"Subject: Artificial Intelligence\\nProblem: Making travel easier\",\n          \"Artificial intelligence will overtake humans in the next century.\",\n          \"Unease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2980,\n        \"samples\": [\n          \"If we don't reach our goals and dreams, we won't have it all, it won't be complete.\",\n          \"Foreign Direct Investment (FDI) is an investment made by a company or individual from one country into businesses located in another country. This type of investment can be made for various reasons, such as buying new assets, establishing joint ventures, or simply taking an ownership stake in the business. FDI can create jobs and can bring needed capital into the new host country. Additionally, it can result in improved economic opportunities and the sharing of technology, skills and knowledge between businesses.\",\n          \"The American media generally portrays politics in a negative light. News coverage is often focused on the negative aspects of politics and the political process. It often ignores the positive impacts of policy decisions and tends to distort the actual picture of politics \\u2013 often displaying it as a circus of corruption and dysfunction. This depiction of politics can be damaging, as it encourages citizens to think of politicians and those in power as adversaries rather than potential partners or problem solvers.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Create a pseudo-code algorithm to find the maximum number in a given list of numbers. \\u00a0This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. \\u00a0The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%\",\n          \"Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this\",\n          \"Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \\\"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\\\"\\nOr suppose you're writing in, \\\"It's only $9.12 a week, and I can't find any work that's not more reasonable\\\", and that's a half-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliação do Modelo GPT2-Small\n",
        "\n",
        "* Observações: O modelo apresentou dificuldades em interpretar as instruções do dataset escolhido, gerando respostas inconsistentes.\n"
      ],
      "metadata": {
        "id": "fRSHs1PnVa-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melhorias Propostas\n",
        "\n",
        "1.  Divisão estratificada dos datasets (classificação ou clusterização)\n",
        "  - A escolha aleatória das linhas para os datasets de treino e teste é uma abordagem válida, mas pode ser interessante explorar outras estratégias, como a divisão estratificada, para garantir que ambos os datasets representem adequadamente a distribuição dos dados originais.\n",
        "2.  Exploração de modelos maiores (GPT2-Medium, GPT2-Large)\n",
        "  - O GPT2-Small pode ser limitado para tarefas complexas. Podemos considerar em explorar modelos maiores, como o GPT2-Medium ou GPT2-Large, para obter melhores resultados. No entanto, modelos maiores exigem mais recursos computacionais.\n",
        "3.  Fine-tuning do modelo com o dataset de treino\n",
        "  - Ajustar o modelo GPT2-Small com dataset de treinamento pode melhorar significativamente o desempenho. O fine-tuning permite que o modelo se adapte às características específicas dos seus dados. (Esta abordagem foi selecionada para melhorar a resposta do modelo maix abaixo).\n",
        "4.  Aprimoramento da formulação dos prompts\n",
        "  - O ideal seria incluir as informações primárias da coluna 'text' do dataset. No entanto, essa coluna foi removida, pois estava gerando complicações no treinamento do modelo e enviesando o output, que retornava exatamente o que a própria coluna sugeria. Normalmente, datasets não possuem esse tipo de informação; essa coluna, em específico, parece ter sido incluída apenas para fins de estudo."
      ],
      "metadata": {
        "id": "WtMX0SKsWyD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 2"
      ],
      "metadata": {
        "id": "pzM7dA3SGuRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-Tuning"
      ],
      "metadata": {
        "id": "RX7SvlL-G2_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"text\": f\"Instruction: {example['instruction']}\\nInput: {example['input']}\\nOutput: {example['output']}\"\n",
        "    }\n",
        "\n",
        "dataset = dataset_train.map(format_prompt)"
      ],
      "metadata": {
        "id": "84BqSvT1Bc3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0b975953b3ac44439b14592fb93ce1f6",
            "c8e00dc9a7734527821244f6b248dfce",
            "88ab70fc63104b9fbf2f49638b8f62a5",
            "8a660597753444908970e55988eb2539",
            "a747abb624b94c89aa363a632d10747f",
            "f9a0177277584442ab57d096b8d1c683",
            "43a9fb5c50194b389b261742e7c7a5a5",
            "73e900c6725a4acaba0d38943bf8d695",
            "60d6116253ab436d89960f046e049c19",
            "7fea0c2448ae4a84a3aae59edb668e05",
            "04c48443509f4f9da5cc8df0286d57c1"
          ]
        },
        "outputId": "79c97779-edfe-48d4-b5ef-8cb5cd998d1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b975953b3ac44439b14592fb93ce1f6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"ComCom/gpt2-small\")"
      ],
      "metadata": {
        "id": "agFpe01BJAxW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenização do dataset"
      ],
      "metadata": {
        "id": "TqNSAvSR5qN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"ComCom/gpt2-small\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    text_tokenized = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    output_tokenized = tokenizer(examples[\"output\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    return {\n",
        "        \"input_ids\": text_tokenized[\"input_ids\"],\n",
        "        \"attention_mask\": text_tokenized[\"attention_mask\"],\n",
        "        \"labels\": output_tokenized[\"input_ids\"],\n",
        "    }\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "uRVperBvA2eu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "36aa6d2ac3ed4160a1382ba850bd55c4",
            "ffbf064e87ce4e2e9327ab673339fd07",
            "ac86385d15ee4b17b1a7ff3347a00e58",
            "b4c9cf093c8141a1b3fd766284cd3344",
            "6dddf0c87b7941308ac6d24ca540a953",
            "b60949fe3dd641489f36f8c1ff35faf8",
            "4392f4187cbd496bb96f9fb0b3bd55ca",
            "2fc275d328244e70981e2877817ca4a9",
            "0fbf02a169274006b29f1d61d5a23130",
            "3d04a4a8fa794654937c5cb8f03aac04",
            "34af15605cef41d4aaa0c79bfb266862"
          ]
        },
        "outputId": "a1aafce8-3903-40c1-d872-f1d749e88402"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36aa6d2ac3ed4160a1382ba850bd55c4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação dos dados para treino e test\n",
        "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "train_dataset = tokenized_datasets.shuffle(seed=456).select(range(2500))\n",
        "eval_dataset = tokenized_datasets.shuffle(seed=456).select(range(len(tokenized_datasets) - 300, len(tokenized_datasets)))"
      ],
      "metadata": {
        "id": "OC8QH_LF_zjJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O uso do DataCollatorForLanguageModeling é adequado para tarefas de geração de texto.\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "GxUcbUIvFYBR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        "    run_name=\"my-gpt2-test_dataset-run\",\n",
        "    eval_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "wandb.login(key=userdata.get('WANDB_API_KEY'))\n"
      ],
      "metadata": {
        "id": "BQQXc0caCB9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29ff4d3-c7e0-41c7-a0d5-d11f16eb1dc6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoukyto\u001b[0m (\u001b[33mhoukyto-particular\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento do modelo"
      ],
      "metadata": {
        "id": "7nB98Ef7FeIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() # Aplicando os argumentos e treinando o modelo\n",
        "\n",
        "# Tabela summario de métricas de treinamento\n",
        "metrics = {\n",
        "    \"train_runtime\": trainer.state.log_history[-1][\"train_runtime\"],\n",
        "    \"train_samples_per_second\": trainer.state.log_history[-1][\"train_samples_per_second\"],\n",
        "    \"train_steps_per_second\": trainer.state.log_history[-1][\"train_steps_per_second\"],\n",
        "    \"train_loss\": trainer.state.log_history[-1][\"train_loss\"],\n",
        "    \"epoch\": trainer.state.log_history[-1][\"epoch\"]\n",
        "}\n",
        "\n",
        "df_train_output = pd.DataFrame([metrics])\n",
        "\n",
        "df_train_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "T7bra8T_Gucq",
        "outputId": "db264492-de70-4b2e-bba6-0e5f92182eb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250503_144459-33zcv4mp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/houkyto-particular/huggingface/runs/33zcv4mp' target=\"_blank\">my-gpt2-test_dataset-run</a></strong> to <a href='https://wandb.ai/houkyto-particular/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/houkyto-particular/huggingface' target=\"_blank\">https://wandb.ai/houkyto-particular/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/houkyto-particular/huggingface/runs/33zcv4mp' target=\"_blank\">https://wandb.ai/houkyto-particular/huggingface/runs/33zcv4mp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3130/3130 31:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.247200</td>\n",
              "      <td>2.162754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.043700</td>\n",
              "      <td>2.129907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.997700</td>\n",
              "      <td>2.125949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.980400</td>\n",
              "      <td>2.128057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.845200</td>\n",
              "      <td>2.132505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.807300</td>\n",
              "      <td>2.140540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.826000</td>\n",
              "      <td>2.145466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.688600</td>\n",
              "      <td>2.155646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.699200</td>\n",
              "      <td>2.158149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.571800</td>\n",
              "      <td>2.160263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
              "0      1887.5693                    13.245                   1.658   \n",
              "\n",
              "   train_loss  epoch  \n",
              "0    1.879895   10.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aed4475-2eb7-49c6-a553-58bd6cc40668\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1887.5693</td>\n",
              "      <td>13.245</td>\n",
              "      <td>1.658</td>\n",
              "      <td>1.879895</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aed4475-2eb7-49c6-a553-58bd6cc40668')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6aed4475-2eb7-49c6-a553-58bd6cc40668 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6aed4475-2eb7-49c6-a553-58bd6cc40668');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2d3d1281-9093-4005-95f7-d3a23a4a74a0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train_output')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d3d1281-9093-4005-95f7-d3a23a4a74a0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train_output');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_output",
              "summary": "{\n  \"name\": \"df_train_output\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"train_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1887.5693,\n        \"max\": 1887.5693,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1887.5693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13.245,\n        \"max\": 13.245,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13.245\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.658,\n        \"max\": 1.658,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.8798946935147904,\n        \"max\": 1.8798946935147904,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.8798946935147904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 10.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa, o modelo GPT2-Small foi ajustado (fine-tuning) utilizando o dataset de treino. O objetivo foi adaptar o modelo às características específicas dos dados, melhorando seu desempenho na geração de texto com base nas instruções fornecidas.\n",
        "\n",
        "#### Etapas Realizadas\n",
        "\n",
        "1.  **Formatação dos Prompts:**\n",
        "    * As instruções, entradas e saídas do dataset de treino foram formatadas em um formato de prompt adequado para o modelo.\n",
        "    * A função `format_prompt` foi utilizada para combinar essas informações em um texto único.\n",
        "\n",
        "2.  **Tokenização dos Dados:**\n",
        "    * O dataset de treino foi tokenizado utilizando o tokenizador do GPT2-Small.\n",
        "    * A função `tokenize_function` converteu os textos formatados em sequências de tokens, prontas para serem processadas pelo modelo.\n",
        "    * O parâmetro `max_length` foi ajustado para 256, permitindo sequências de texto mais longas. (Também pode ser ajustado para o tamanho médio das sequências do seu dataset para definir um max_length otimizado)\n",
        "\n",
        "3.  **Preparação dos Datasets de Treino e Avaliação:**\n",
        "    * O dataset tokenizado foi dividido em conjuntos de treino e avaliação.\n",
        "    * O `DataCollatorForLanguageModeling` foi utilizado para criar lotes de dados para o treinamento.\n",
        "\n",
        "4.  **Treinamento do Modelo:**\n",
        "    * O `Trainer` da biblioteca `transformers` foi utilizado para ajustar o modelo GPT2-Small.\n",
        "    * Os hiperparâmetros de treinamento foram definidos nos `TrainingArguments`, incluindo a taxa de aprendizado, o número de épocas e o tamanho do lote.\n",
        "    * O parâmetro `eval_strategy` foi definido como `'epoch'`, permitindo a avaliação do modelo ao final de cada época.\n",
        "    * O parâmetro `save_strategy` foi definido como `'epoch'`, permitindo gravar o modelo em cada época.    \n",
        "    * O parâmetro `load_best_model_at_end` foi adicionado para salvar o melhor modelo com base na métrica de avaliação.\n",
        "    * O monitoramento do treinamento foi realizado utilizando o `wandb`.\n",
        "\n",
        "5.  **Avaliação do Treinamento:**\n",
        "    * As métricas de treinamento foram coletadas e exibidas em um DataFrame, incluindo o tempo de treinamento, a perda e a época.\n",
        "\n",
        "### Análises e Melhorias\n",
        "\n",
        "* O ajuste dos hiperparâmetros, como o número de épocas `epochs` e o tamanho do lote, pode ter um impacto significativo no desempenho do modelo. Pode-se explorar diferentes valores para esses hiperparâmetros, equilibrando o custo computacional e a perforance do treinamento.\n",
        "* A avaliação durante o treinamento, permitida pelo parâmetro `eval_strategy`, ajuda a monitorar o desempenho do modelo e evitar o overfitting.\n",
        "* O salvamento do melhor modelo, ativado pelo parâmetro `load_best_model_at_end`, garante que o modelo com o melhor desempenho seja utilizado.\n",
        "* Aumentar o `max_length` na tokenização permite que o modelo processe sequências de texto mais longas, preservando mais informações.\n",
        "* O uso de técnicas de Parameter-Efficient Fine-Tuning (PEFT), como LoRA, pode reduzir o consumo de memória durante o treinamento.\n"
      ],
      "metadata": {
        "id": "EyMbv0JQYsGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 3"
      ],
      "metadata": {
        "id": "DYVdWiG30ylM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Realizando o teste após o ajuste do modelo"
      ],
      "metadata": {
        "id": "XVgTav5pBm9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(instruction, model, tokenizer, seed=456):\n",
        "    prompt = f\"Instruction: {instruction}\\nOutput:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=128, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    generated_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_output.split(\"Output:\")[1].strip()\n",
        "\n",
        "test_example = dataset[9]\n",
        "instruction = test_example['instruction']+' '+test_example['input']\n",
        "input = test_example['input']\n",
        "output = test_example['output']\n",
        "generated_output = generate_output(instruction, model, tokenizer)\n",
        "print(f\"Instruction Test: {instruction}\")\n",
        "print(f\"Input Test: {input}\")\n",
        "print(f\"Expected Output: {output}\")\n",
        "print(f\"Generated Output: {generated_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoNWZYG__dM5",
        "outputId": "e98d05b4-515a-4e8d-8ea1-8f43d7737fe4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction Test: Evaluate this sentence for spelling and grammar mistakes He finnished his meal and left the resturant\n",
            "Input Test: He finnished his meal and left the resturant\n",
            "Expected Output: He finished his meal and left the restaurant.\n",
            "Generated Output: He finished his dinner and departed the dining room. He was greeted by a group of people, including a woman who was wearing a bright red dress and a blue dress. She smiled and waved goodbye to him.\n",
            "Input: \n",
            "\n",
            "She smiled back and said, \"Good evening, everyone.\"\n",
            "   She walked to the table and sat down.  Her eyes were wide and she looked up at him with a smile. Her heart was pounding and her eyes filled with tears. The woman smiled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_example = dataset[7]\n",
        "instruction = test_example['instruction']+ ' '+test_example['input']\n",
        "input = test_example['input']\n",
        "output = test_example['output']\n",
        "generated_output = generate_output(instruction, model, tokenizer)\n",
        "print(f\"Instruction Test: {instruction}\")\n",
        "print(f\"Input Test: {input}\")\n",
        "print(f\"Expected Output: {output}\")\n",
        "print(f\"Generated Output: {generated_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMn_O8aI-wQx",
        "outputId": "16ffe1d8-3c4e-4cf8-c80e-9aafedfb0751"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction Test: Write a short story in third person narration about a protagonist who has to make an important career decision. \n",
            "Input Test: \n",
            "Expected Output: John was at a crossroads in his life. He had just graduated college and was now facing the big decision of what career to pursue. After much deliberation, he decided that he wanted to be an accountant and help the financially disadvantaged. He had always been good with numbers and enjoyed seeing the tangible results of his work. \n",
            "\n",
            "John enrolled in accounting courses and initially found it quite challenging. He had to learn multiple systems and regulations quickly, but he worked hard and eventually excelled in his studies. After a few years, John started working at an accounting firm in his city. He was eager to put his knowledge of taxes and accounting to use in a real-world setting.\n",
            "\n",
            "John loved his job, as it let him express his creativity in finding strategies to save his clients money. After a few years at the firm, he became a senior accountant and was asked to manage bigger and more challenging cases. He was now a respected figure in the financial industry, but he still remembers when he was just a recent college graduate, unsure of the direction in which his life would take him.\n",
            "Generated Output: The protagonist is a young man who is struggling to find his way in life. He is determined to pursue his dreams and pursue a career in the field of medicine. But he is also determined not to let his past lead him to failure. His life is filled with obstacles and struggles, and he must make a difficult decision to reach his goal.\n",
            "\n",
            "The story follows the protagonist as he struggles to overcome his struggles and find a way to live a fulfilling life in a world that is full of obstacles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Incluindo a nova coluna no data frame: df_test_gpt2\n",
        "\n"
      ],
      "metadata": {
        "id": "IXubup5KFLBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_gpt2['text_generated_new'] = None\n",
        "\n",
        "for index in range(10):\n",
        "  instruction = df_test_gpt2.loc[index, 'instruction']\n",
        "  input = df_test_gpt2.loc[index, 'input']\n",
        "  if pd.notnull(input):\n",
        "    instruction_with_input = instruction + ' ' + input\n",
        "    generated_output_new = generate_output(instruction_with_input, model, tokenizer)\n",
        "  else:\n",
        "    generated_output_new = generate_output(instruction, model, tokenizer)\n",
        "\n",
        "  df_test_gpt2.loc[index, 'text_generated_new'] = generated_output_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Q7JMtinlMI",
        "outputId": "30619d29-4bc2-4bb1-ae1b-d39768428a52"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_gpt2.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CyLcSPSIORRF",
        "outputId": "942097fb-ad40-4940-ba82-aa796ea3fa21"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             instruction  \\\n",
              "0                                    Construct a story given a specific theme of choice.   \n",
              "1                                                Retrieve a fact about a specific topic.   \n",
              "2                   Rearrange a paragraph to make it read in an orderly and logical way.   \n",
              "3                                                    Describe a scene to a blind person.   \n",
              "4                                     Translate a sentence from one language to another.   \n",
              "5                                     Given a scenario, decide which is the best advice.   \n",
              "6                                             Find the difference between 11/80 and 0.13   \n",
              "7                                                       Convert the time from GMT to EST   \n",
              "8  Create a pseudo-code algorithm to find the maximum number in a given list of numbers.   \n",
              "9                  Rewrite this English sentence into Spanish: The sun rises in the east   \n",
              "\n",
              "                                                                                                                                                           input  \\\n",
              "0                                                                                                                                              Theme: Friendship   \n",
              "1                                                                                                                                            Topic: Solar System   \n",
              "2  Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.   \n",
              "3                                                                                                                                 A flower garden in the morning   \n",
              "4                                                                                                         Sentence: Je veux aller à la plage.\\nLanguage: Spanish   \n",
              "5                                                       Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.   \n",
              "6                                                                                                                                                                  \n",
              "7                                                                                                                                                  3:25 p.m. GMT   \n",
              "8                                                                                                                                                                  \n",
              "9                                                                                                                                                                  \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    output  \\\n",
              "0                                                                                                                                         Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                        The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                            Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.   \n",
              "3                                                                                                                                                                               The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Quiero ir a la playa.   \n",
              "5                                                                                                                                                                                                                                                              The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                         The difference between 11/80 and 0.13 is 0.0375.   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                       The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.   \n",
              "8  Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 El sol sale por el este.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                           generated_text  \\\n",
              "0  Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a   \n",
              "1                                                               Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this   \n",
              "2                          Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing   \n",
              "3                                                       Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister—or both. A night out, the weather improves as it did on Saturday.\\n\\nIt has   \n",
              "4                                                                                                                                                                                                                                                                                                                                            Translate a sentence from one language to another. Sentence: Je veux aller à la plage.\\nLanguage: Spanish - drei\\nLanguage: French - fédérif   \n",
              "5                                                                               Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-   \n",
              "6                                                      Find the difference between 11/80 and 0.13  or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by   \n",
              "7                                                                                                                                                                                     Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard   \n",
              "8                                                                      Create a pseudo-code algorithm to find the maximum number in a given list of numbers.  This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings.  The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%   \n",
              "9                                                     Rewrite this English sentence into Spanish: The sun rises in the east \\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text_generated_new  \n",
              "0  The protagonist is a young man who is fascinated by the beauty of nature. He is determined to find a way to make it all the more special.\\n\\nThe protagonist's journey begins with a journey to the edge of the world, where he meets a mysterious stranger. The stranger is an old man named John. John is the only person who can remember the past and the present, and he is able to remember everything that happened in the future. As John grows up, he discovers that he can use his memories to create a better future for  \n",
              "1                              The Solar system is a system of planets orbiting the Sun. It is composed of three main planets, Mercury, Uranus and Neptune. Mercury orbits the Earth at a distance of about 1,200 light-years. Uranium orbits Saturn at an angle of approximately 1.5 degrees. Neptune orbits Jupiter at the same angle. The Sun is the only planet in the Solar systems that is not surrounded by matter.\\n\\nThe Sun orbits its axis of rotation at about 7.8 degrees per year. Its distance from the sun is about 5,  \n",
              "2                                                                                                                      The next steps to be taken are to identify patterns in data and to use the visualizations to better understand the underlying patterns. The data should be analyzed and analyzed to determine the best way to interpret the results. Finally, the user should have the opportunity to interact with the app and interactivity should improve. This is a great way for Alexa to help users understand their data  \n",
              "3                                                   The scene in question is a flower growing in a garden. The flower is surrounded by a large, green, and yellow flower. It is blooming in mid-summer and is usually a beautiful sight. In the evening, the flower blooms in an open field, surrounded on all sides by trees and bushes. On the day, it is in full bloom and bloomes in late summer. During the summer, when the sun is shining brightly, flowers are bloating in open fields and in summertime, they are usually blo  \n",
              "4                                                                                                                                                                                                                                              The plages were a kind of portable furniture. They were made of wood, and were usually made to last for years. Je vous avez un plaît, le plager de la Plage de l'Avant-Garde. \\n\\nJe voulez un peuvent de plagiarisme, mais le monde de leurs plagers de Plagieux. Il est un même de mé  \n",
              "5                                                                    The best way to plan for a job in the new state is to stay in touch with your new employer and make sure that you have the necessary skills and experience to make the decision. Additionally, you should consider the benefits of staying in contact with the company and the potential benefits that come with staying connected to them. Finally, make a plan to get to know your current employer better and to ensure that they have a good understanding of  \n",
              "6                                                          11.83 is the average of the 11th and 12th centuries. It is equivalent to the 12 th and 13 th centuries, respectively. The difference is that 11 is shorter than 0, whereas 12 is longer than 11, while 13 is equal to 0 and 11 are equal. Therefore, 11 has a shorter average than 12, and it is therefore equivalent.\\n\\n12.14 is a measure of how long a given period is. This is calculated by dividing the length of a period by the number of years. For example, if a  \n",
              "7                                                                                                                                                  The time to arrive at the airport is 3 p, 19:00. The airport will be open from 9:30 a.M. to 5:45 p., and will open at 5 p ET.\\nInput: \\n\\nThe time for arriving at airport at 3 pm is 9 p EST. This means that the arrival time will start at 9 pm and end at 11:59 pm. Therefore, the estimated arrival times for the following airports are:\\nTokyo, Tokyo, and Tokyo-Mitsubishi.  \n",
              "8                                                                                                                                                                                                                           1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\nInput  \n",
              "9                                                     He rises with the sun in his sky.\\n\\nThe sun is rising in a bright and beautiful sky, shining like a beacon of light. He is the star of the night, and the stars are the light of day. The stars shine like stars, illuminating the world and making it brighter and brighter. They are like the rays of sunlight, making the sky brighter, brighter than ever before. It is a beautiful day, filled with stars and shadows, but it is also a time of peace and joy.  The sky is  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd7e8602-09ec-448d-b866-e164abeb6ec6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>generated_text</th>\n",
              "      <th>text_generated_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Construct a story given a specific theme of choice.</td>\n",
              "      <td>Theme: Friendship</td>\n",
              "      <td>Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.</td>\n",
              "      <td>Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a</td>\n",
              "      <td>The protagonist is a young man who is fascinated by the beauty of nature. He is determined to find a way to make it all the more special.\\n\\nThe protagonist's journey begins with a journey to the edge of the world, where he meets a mysterious stranger. The stranger is an old man named John. John is the only person who can remember the past and the present, and he is able to remember everything that happened in the future. As John grows up, he discovers that he can use his memories to create a better future for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Retrieve a fact about a specific topic.</td>\n",
              "      <td>Topic: Solar System</td>\n",
              "      <td>The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.</td>\n",
              "      <td>Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this</td>\n",
              "      <td>The Solar system is a system of planets orbiting the Sun. It is composed of three main planets, Mercury, Uranus and Neptune. Mercury orbits the Earth at a distance of about 1,200 light-years. Uranium orbits Saturn at an angle of approximately 1.5 degrees. Neptune orbits Jupiter at the same angle. The Sun is the only planet in the Solar systems that is not surrounded by matter.\\n\\nThe Sun orbits its axis of rotation at about 7.8 degrees per year. Its distance from the sun is about 5,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way.</td>\n",
              "      <td>Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.</td>\n",
              "      <td>Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.</td>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing</td>\n",
              "      <td>The next steps to be taken are to identify patterns in data and to use the visualizations to better understand the underlying patterns. The data should be analyzed and analyzed to determine the best way to interpret the results. Finally, the user should have the opportunity to interact with the app and interactivity should improve. This is a great way for Alexa to help users understand their data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Describe a scene to a blind person.</td>\n",
              "      <td>A flower garden in the morning</td>\n",
              "      <td>The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.</td>\n",
              "      <td>Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister—or both. A night out, the weather improves as it did on Saturday.\\n\\nIt has</td>\n",
              "      <td>The scene in question is a flower growing in a garden. The flower is surrounded by a large, green, and yellow flower. It is blooming in mid-summer and is usually a beautiful sight. In the evening, the flower blooms in an open field, surrounded on all sides by trees and bushes. On the day, it is in full bloom and bloomes in late summer. During the summer, when the sun is shining brightly, flowers are bloating in open fields and in summertime, they are usually blo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Translate a sentence from one language to another.</td>\n",
              "      <td>Sentence: Je veux aller à la plage.\\nLanguage: Spanish</td>\n",
              "      <td>Quiero ir a la playa.</td>\n",
              "      <td>Translate a sentence from one language to another. Sentence: Je veux aller à la plage.\\nLanguage: Spanish - drei\\nLanguage: French - fédérif</td>\n",
              "      <td>The plages were a kind of portable furniture. They were made of wood, and were usually made to last for years. Je vous avez un plaît, le plager de la Plage de l'Avant-Garde. \\n\\nJe voulez un peuvent de plagiarisme, mais le monde de leurs plagers de Plagieux. Il est un même de mé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Given a scenario, decide which is the best advice.</td>\n",
              "      <td>Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.</td>\n",
              "      <td>The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.</td>\n",
              "      <td>Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-</td>\n",
              "      <td>The best way to plan for a job in the new state is to stay in touch with your new employer and make sure that you have the necessary skills and experience to make the decision. Additionally, you should consider the benefits of staying in contact with the company and the potential benefits that come with staying connected to them. Finally, make a plan to get to know your current employer better and to ensure that they have a good understanding of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Find the difference between 11/80 and 0.13</td>\n",
              "      <td></td>\n",
              "      <td>The difference between 11/80 and 0.13 is 0.0375.</td>\n",
              "      <td>Find the difference between 11/80 and 0.13  or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by</td>\n",
              "      <td>11.83 is the average of the 11th and 12th centuries. It is equivalent to the 12 th and 13 th centuries, respectively. The difference is that 11 is shorter than 0, whereas 12 is longer than 11, while 13 is equal to 0 and 11 are equal. Therefore, 11 has a shorter average than 12, and it is therefore equivalent.\\n\\n12.14 is a measure of how long a given period is. This is calculated by dividing the length of a period by the number of years. For example, if a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Convert the time from GMT to EST</td>\n",
              "      <td>3:25 p.m. GMT</td>\n",
              "      <td>The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.</td>\n",
              "      <td>Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard</td>\n",
              "      <td>The time to arrive at the airport is 3 p, 19:00. The airport will be open from 9:30 a.M. to 5:45 p., and will open at 5 p ET.\\nInput: \\n\\nThe time for arriving at airport at 3 pm is 9 p EST. This means that the arrival time will start at 9 pm and end at 11:59 pm. Therefore, the estimated arrival times for the following airports are:\\nTokyo, Tokyo, and Tokyo-Mitsubishi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers.</td>\n",
              "      <td></td>\n",
              "      <td>Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.</td>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers.  This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings.  The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%</td>\n",
              "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\nInput</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east</td>\n",
              "      <td></td>\n",
              "      <td>El sol sale por el este.</td>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east \\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time</td>\n",
              "      <td>He rises with the sun in his sky.\\n\\nThe sun is rising in a bright and beautiful sky, shining like a beacon of light. He is the star of the night, and the stars are the light of day. The stars shine like stars, illuminating the world and making it brighter and brighter. They are like the rays of sunlight, making the sky brighter, brighter than ever before. It is a beautiful day, filled with stars and shadows, but it is also a time of peace and joy.  The sky is</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd7e8602-09ec-448d-b866-e164abeb6ec6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd7e8602-09ec-448d-b866-e164abeb6ec6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd7e8602-09ec-448d-b866-e164abeb6ec6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-52bdfcab-1d3a-477b-bf6a-6e185f67d904\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52bdfcab-1d3a-477b-bf6a-6e185f67d904')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-52bdfcab-1d3a-477b-bf6a-6e185f67d904 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_gpt2",
              "summary": "{\n  \"name\": \"df_test_gpt2\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"Answer a trivia question related to this context.\",\n          \"What is a common use case for a machine learning algorithm?\",\n          \"Compare and contrast the characteristics of the desert and the jungle.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1169,\n        \"samples\": [\n          \"Subject: Artificial Intelligence\\nProblem: Making travel easier\",\n          \"Artificial intelligence will overtake humans in the next century.\",\n          \"Unease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2980,\n        \"samples\": [\n          \"If we don't reach our goals and dreams, we won't have it all, it won't be complete.\",\n          \"Foreign Direct Investment (FDI) is an investment made by a company or individual from one country into businesses located in another country. This type of investment can be made for various reasons, such as buying new assets, establishing joint ventures, or simply taking an ownership stake in the business. FDI can create jobs and can bring needed capital into the new host country. Additionally, it can result in improved economic opportunities and the sharing of technology, skills and knowledge between businesses.\",\n          \"The American media generally portrays politics in a negative light. News coverage is often focused on the negative aspects of politics and the political process. It often ignores the positive impacts of policy decisions and tends to distort the actual picture of politics \\u2013 often displaying it as a circus of corruption and dysfunction. This depiction of politics can be damaging, as it encourages citizens to think of politicians and those in power as adversaries rather than potential partners or problem solvers.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Create a pseudo-code algorithm to find the maximum number in a given list of numbers. \\u00a0This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. \\u00a0The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%\",\n          \"Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this\",\n          \"Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \\\"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\\\"\\nOr suppose you're writing in, \\\"It's only $9.12 a week, and I can't find any work that's not more reasonable\\\", and that's a half-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_generated_new\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\nInput\",\n          \"The Solar system is a system of planets orbiting the Sun. It is composed of three main planets, Mercury, Uranus and Neptune. Mercury orbits the Earth at a distance of about 1,200 light-years. Uranium orbits Saturn at an angle of approximately 1.5 degrees. Neptune orbits Jupiter at the same angle. The Sun is the only planet in the Solar systems that is not surrounded by matter.\\n\\nThe Sun orbits its axis of rotation at about 7.8 degrees per year. Its distance from the sun is about 5,\",\n          \"The best way to plan for a job in the new state is to stay in touch with your new employer and make sure that you have the necessary skills and experience to make the decision. Additionally, you should consider the benefits of staying in contact with the company and the potential benefits that come with staying connected to them. Finally, make a plan to get to know your current employer better and to ensure that they have a good understanding of\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Avaliando a qualidade do resultado após o treinamento do modelo:\n",
        "\n",
        "Após treinar o modelo com o dataset vimos que ele conseguiu adptar um pouco melhor as repostas, porém ainda é necessário alguns ajustes.\n",
        "Como alternativa alguns parâmetros podem ser ajustados para retreinar o modelo, porém sem prejudicar no custo computacional."
      ],
      "metadata": {
        "id": "3WC1Qn89WgnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo GPT2-Small ajustado na Etapa 2 foi utilizado para gerar respostas/outputs para as instruções do dataset de teste. O objetivo foi avaliar o impacto do fine-tuning no desempenho do modelo.\n",
        "\n",
        "* Análises:\n",
        "\n",
        "1.  **Geração de Respostas com o Modelo Ajustado:**\n",
        "\n",
        "    * A função `generate_output`, que utiliza o modelo ajustado para gerar respostas com base nas instruções fornecidas. A função tokeniza as instruções, gera as respostas e as decodifica. Em seguida, o código itera sobre os exemplos do dataset de teste, gera as respostas e as armazena em uma nova coluna do DataFrame `df_test_gpt2`.\n",
        "    * **Análise:** Ao comparar as respostas geradas pelo modelo ajustado com as respostas esperadas, observamos uma melhora na qualidade das respostas em relação à Etapa 1. No entanto, ainda há espaço para otimização.\n",
        "\n",
        "2.  **Avaliação da Qualidade do Resultado:**\n",
        "\n",
        "    * A avaliação da qualidade das respostas foi realizada de forma qualitativa, comparando as respostas geradas com as respostas esperadas. Para uma avaliação mais precisa, pode-se fazer uso de métricas quantitativas, como *BLEU*, *ROUGE* ou *Perplexidade*.\n",
        "    * **Análise:** O modelo ajustado demonstrou uma melhoria na capacidade de gerar respostas coerentes e relevantes, mas ainda apresenta dificuldades em algumas instruções mais complexas.\n",
        "\n",
        "3.  **Agrupamento por Temas:**\n",
        "\n",
        "    * Uma abordagem eficaz seria utilizar um modelo *GPT2 Text-Classification*, por exemplo, para classificar as perguntas em diferentes categorias de temas. O modelo seria ajustado com um dataset de treinamento contendo perguntas e suas respectivas categorias. Em seguida, o modelo seria utilizado para classificar as perguntas dos datasets de treino e teste.\n",
        "    * A utilização de um modelo GPT2-Classification permite aproveitar o poder dos modelos de linguagem para agrupar as perguntas de forma semântica, considerando o significado das palavras e frases.\n",
        "    * **Alternativa:** Outra alternativa seria utilizar técnicas de incorporação de palavras (Word Embeddings) ou modelos de tópicos (Topic Modeling) para agrupar as perguntas por temas semelhantes.\n",
        "\n",
        "#### Código Sugerido para agrupamento por temas (Utilizando Sentence Transformers)\n",
        "\n",
        "```\n",
        "    # Importando dependências\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # Carregando o modelo Sentence Transformer\n",
        "    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "    # Obtendo as perguntas dos datasets\n",
        "    questions = list(df_train['text']) + list(df_test['text'])\n",
        "\n",
        "    # Gerando os embeddings das perguntas\n",
        "    embeddings = model.encode(questions)\n",
        "\n",
        "    # Agrupando as perguntas usando K-means\n",
        "    num_clusters = 5\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(embeddings)\n",
        "\n",
        "    # Obtendo os rótulos dos clusters\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Imprimindo os resultados\n",
        "    for i in range(num_clusters):\n",
        "        print(f\"Cluster {i}:\")\n",
        "        for j, label in enumerate(labels):\n",
        "            if label == i:\n",
        "                print(questions[j])\n",
        "        print()\n",
        "```"
      ],
      "metadata": {
        "id": "wxIV3xoEcuLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Agrupamento por Temas (Utilizando Sentence Transformers)\n",
        "\n",
        "* O código utiliza a biblioteca `sentence_transformers` para gerar embeddings de sentenças, que representam o significado das perguntas.\n",
        "* O modelo `distilbert-base-nli-mean-tokens` é utilizado para gerar os embeddings.\n",
        "* O algoritmo K-means é utilizado para agrupar as perguntas com base em seus embeddings.\n",
        "* O número de clusters (`num_clusters`) pode ser ajustado de acordo com o número desejado de grupos de perguntas.\n",
        "* Os rótulos dos clusters são obtidos e utilizados para imprimir as perguntas em cada grupo.\n",
        "\n",
        "#### Melhorias Futuras para agrupar os temas\n",
        "\n",
        "* Explorar diferentes modelos de Sentence Transformers para obter embeddings mais precisos.\n",
        "* Experimentar diferentes algoritmos de agrupamento, como DBSCAN ou agrupamento hierárquico.\n",
        "* Utilizar técnicas de redução de dimensionalidade, como PCA ou t-SNE, para visualizar os clusters em um espaço bidimensional ou tridimensional.\n",
        "* Automatizar a seleção do número ideal de clusters utilizando técnicas como o método do cotovelo ou a pontuação de silhueta.\n",
        "* Avaliar a qualidade dos clusters utilizando métricas como o índice Davies-Bouldin ou o índice de silhueta.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FU_4qbi7e5QY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#### Considerações Finais\n",
        "\n",
        "Ao longo das Etapas 1, 2 e 3, foi explorado o fine-tuning do modelo GPT2-Small para a geração de texto com base em instruções específicas. Observamos que o fine-tuning resultou em melhorias na qualidade das respostas geradas pelo modelo, demonstrando a eficácia da adaptação do modelo aos dados específicos do projeto. No entanto, ainda há espaço para otimização e aprimoramento do modelo.\n",
        "\n",
        "#### Melhorias Futuras\n",
        "\n",
        "#### Aprimoramento do Fine-tuning:\n",
        "\n",
        "* **Exploração de Hiperparâmetros:** Realizar uma busca mais abrangente de hiperparâmetros, como taxa de aprendizado, tamanho do lote e número de épocas, para encontrar a configuração ideal para o modelo.\n",
        "* **Técnicas de Regularização:** Implementar técnicas de regularização, como dropout ou weight decay, para evitar o overfitting e melhorar a generalização do modelo.\n",
        "* **Modelos Maiores:** Experimentar modelos GPT2 maiores, como GPT2-Medium ou GPT2-Large, para avaliar se eles oferecem melhorias significativas no desempenho. No entanto, é importante considerar os custos computacionais associados a modelos maiores.\n",
        "* **Fine-tuning Eficiente:** Explorar técnicas de fine-tuning eficientes, como o Parameter-Efficient Fine-Tuning (PEFT), para reduzir o consumo de memória e o tempo de treinamento.\n",
        "\n",
        "#### Otimização da Geração de Texto:\n",
        "\n",
        "* **Ajuste de Parâmetros de Geração:** Experimentar diferentes valores para os parâmetros de geração, como `temperature`, `top_k` e `top_p`, para controlar a criatividade e a diversidade das respostas geradas.\n",
        "* **Prompt Engineering:** Aprimorar a formulação dos prompts, adicionando instruções mais detalhadas ou exemplos, para orientar o modelo na geração de respostas mais precisas e relevantes.\n",
        "* **Modelos de Linguagem Condicionados:** Explorar modelos de linguagem condicionados, como T5 ou BART, que são projetados para tarefas de geração de texto com base em instruções ou entradas específicas.\n",
        "\n",
        "#### Avaliação Abrangente:\n",
        "\n",
        "* **Métricas Quantitativas:** Utilizar uma variedade de métricas quantitativas, como BLEU, ROUGE e Perplexidade, para avaliar o desempenho do modelo de forma mais abrangente e objetiva.\n",
        "* **Avaliação Humana:** Realizar avaliações humanas para avaliar a qualidade das respostas geradas pelo modelo em termos de relevância, coerência e fluência.\n",
        "* **Análise de Erros:** Realizar uma análise detalhada dos erros cometidos pelo modelo para identificar padrões e áreas de melhoria.\n",
        "\n",
        "#### Agrupamento e Categorização:\n",
        "\n",
        "* **Modelos de Classificação:** Investigar o uso de modelos de classificação de texto, como BERT ou RoBERTa, para categorizar as perguntas por tópicos ou temas relevantes.\n",
        "* **Modelos de Tópicos:** Aplicar modelos de tópicos, como LDA ou NMF, para identificar os principais tópicos presentes nas perguntas e agrupar perguntas semelhantes.\n",
        "* **Embeddings de Sentenças:** Explorar o uso de embeddings de sentenças, como Sentence Transformers, para representar as perguntas em um espaço vetorial e agrupar perguntas semanticamente semelhantes.\n",
        "\n",
        "Ao implementar essas melhorias futuras, podemos aprimorar ainda mais o modelo GPT2-Small e obter resultados mais precisos e relevantes na geração de texto com base em instruções específicas."
      ],
      "metadata": {
        "id": "7bsqGdkygY7F"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTK5gY8gtZ0sODUrGKEd2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b975953b3ac44439b14592fb93ce1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8e00dc9a7734527821244f6b248dfce",
              "IPY_MODEL_88ab70fc63104b9fbf2f49638b8f62a5",
              "IPY_MODEL_8a660597753444908970e55988eb2539"
            ],
            "layout": "IPY_MODEL_a747abb624b94c89aa363a632d10747f"
          }
        },
        "c8e00dc9a7734527821244f6b248dfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a0177277584442ab57d096b8d1c683",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_43a9fb5c50194b389b261742e7c7a5a5",
            "value": "Map:‚Äá100%"
          }
        },
        "88ab70fc63104b9fbf2f49638b8f62a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e900c6725a4acaba0d38943bf8d695",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60d6116253ab436d89960f046e049c19",
            "value": 3000
          }
        },
        "8a660597753444908970e55988eb2539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fea0c2448ae4a84a3aae59edb668e05",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_04c48443509f4f9da5cc8df0286d57c1",
            "value": "‚Äá3000/3000‚Äá[00:00&lt;00:00,‚Äá12747.92‚Äáexamples/s]"
          }
        },
        "a747abb624b94c89aa363a632d10747f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a0177277584442ab57d096b8d1c683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a9fb5c50194b389b261742e7c7a5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e900c6725a4acaba0d38943bf8d695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d6116253ab436d89960f046e049c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fea0c2448ae4a84a3aae59edb668e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c48443509f4f9da5cc8df0286d57c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36aa6d2ac3ed4160a1382ba850bd55c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffbf064e87ce4e2e9327ab673339fd07",
              "IPY_MODEL_ac86385d15ee4b17b1a7ff3347a00e58",
              "IPY_MODEL_b4c9cf093c8141a1b3fd766284cd3344"
            ],
            "layout": "IPY_MODEL_6dddf0c87b7941308ac6d24ca540a953"
          }
        },
        "ffbf064e87ce4e2e9327ab673339fd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b60949fe3dd641489f36f8c1ff35faf8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4392f4187cbd496bb96f9fb0b3bd55ca",
            "value": "Map:‚Äá100%"
          }
        },
        "ac86385d15ee4b17b1a7ff3347a00e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc275d328244e70981e2877817ca4a9",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fbf02a169274006b29f1d61d5a23130",
            "value": 3000
          }
        },
        "b4c9cf093c8141a1b3fd766284cd3344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d04a4a8fa794654937c5cb8f03aac04",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_34af15605cef41d4aaa0c79bfb266862",
            "value": "‚Äá3000/3000‚Äá[00:03&lt;00:00,‚Äá772.88‚Äáexamples/s]"
          }
        },
        "6dddf0c87b7941308ac6d24ca540a953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60949fe3dd641489f36f8c1ff35faf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4392f4187cbd496bb96f9fb0b3bd55ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc275d328244e70981e2877817ca4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbf02a169274006b29f1d61d5a23130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d04a4a8fa794654937c5cb8f03aac04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34af15605cef41d4aaa0c79bfb266862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ferstuque/AI_and_data/blob/main/LLM_GPT2_Fine_Tuning_HuggingFace_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook - Fine-tuning do GPT2-Small para Gera√ß√£o de Texto com Dataset da Hugging Face\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8BECthl934nx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook apresenta um exemplo pr√°tico de como integrar um modelo de linguagem grande GPT-2 Small pr√©-treinado e um dataset, ambos fornecidos pelo Hugging Face. O conte√∫do est√° dividido em tr√™s etapas, que incluem uma an√°lise detalhada e potenciais otimiza√ß√µes para o modelo de gera√ß√£o de texto."
      ],
      "metadata": {
        "id": "IgQzUCmkGA8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üì£ √â altamente recomendado que utilize um cluster de GPU do Google Colab para performar este notebook."
      ],
      "metadata": {
        "id": "eBYyLoGeTH6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate evaluate bert-score nltk\n",
        "!pip install git-lfs"
      ],
      "metadata": {
        "id": "u_vCoNjPVGKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checando se o GPU NVIDIA est√° habilitado\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9SwoKCbekrgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Instalando dependencias"
      ],
      "metadata": {
        "id": "CmuYhWtzbFY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from transformers import (pipeline,\n",
        "                          set_seed,\n",
        "                          AutoTokenizer,\n",
        "                          GPT2LMHeadModel,\n",
        "                          GPT2Tokenizer,\n",
        "                          GPT2Config,\n",
        "                          GPT2ForSequenceClassification,\n",
        "                          TrainingArguments,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          Trainer,\n",
        "                          get_linear_schedule_with_warmup,\n",
        "                          AutoModelForCausalLM)\n",
        "from google.colab import userdata\n",
        "import evaluate\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "\n",
        "torch.manual_seed(456)\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "j7JtpzhqZ9yz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 1"
      ],
      "metadata": {
        "id": "Mv8d_Jbs5dVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divis√£o dos Datasets\n",
        "\n",
        "* Dataset de treino: 3000 linhas (escolha aleat√≥ria)\n",
        "* Dataset de teste: 3000 linhas (escolha aleat√≥ria)"
      ],
      "metadata": {
        "id": "8WOjg-eCUCg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "--2Up4AVUcAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  dataset_train = load_dataset(\"tatsu-lab/alpaca\", split=\"train[:3000]\").remove_columns(['text'])\n",
        "  dataset_test = load_dataset(\"tatsu-lab/alpaca\", split=\"train[-3000:]\").remove_columns(['text'])\n",
        "  print(f'Train:\\n{dataset_train}')\n",
        "  print(f'Test:\\n{dataset_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xr8A4a3VUr1",
        "outputId": "506c54d0-ceed-461d-d90c-680b871dc348"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output'],\n",
            "    num_rows: 3000\n",
            "})\n",
            "Test:\n",
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output'],\n",
            "    num_rows: 3000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_test[0]['instruction'])\n",
        "print(dataset_test[0]['input'])\n",
        "print(dataset_test[0]['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm8Z1q4f4Oyk",
        "outputId": "5c8d729f-194d-4b8d-ae9f-b6d275b8bad4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Construct a story given a specific theme of choice.\n",
            "Theme: Friendship\n",
            "Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do modelo com frase aleat√≥ria\n",
        "generator = pipeline('text-generation', model='ComCom/gpt2-small', truncation=True)\n",
        "set_seed(456)\n",
        "generator(\"I read epic novel books\", max_length=100, num_return_sequences=1)"
      ],
      "metadata": {
        "id": "koJoYSGN5kOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_gpt2 = pd.DataFrame(dataset_test)\n",
        "df_test_gpt2['generated_text'] = None\n",
        "\n",
        "for index in range(10): # Limitando a apenas 10 linhas de exemplo\n",
        "  instruction = df_test_gpt2.loc[index, 'instruction'] + \" \" + df_test_gpt2.loc[index, 'input']\n",
        "  generated_text = generator(instruction, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
        "  df_test_gpt2.loc[index, 'generated_text'] = generated_text"
      ],
      "metadata": {
        "id": "Beh1i_nn6P2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75c2506-3bf4-4eaa-a771-4a925e7155df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analisando a qualidade do resultado do modelo"
      ],
      "metadata": {
        "id": "6ixzS9-I7VV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "df_test_gpt2.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s0hemclR7UfE",
        "outputId": "6a0c1db7-9c1b-4e20-f159-84c2f9123261"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             instruction  \\\n",
              "0                                    Construct a story given a specific theme of choice.   \n",
              "1                                                Retrieve a fact about a specific topic.   \n",
              "2                   Rearrange a paragraph to make it read in an orderly and logical way.   \n",
              "3                                                    Describe a scene to a blind person.   \n",
              "4                                     Translate a sentence from one language to another.   \n",
              "5                                     Given a scenario, decide which is the best advice.   \n",
              "6                                             Find the difference between 11/80 and 0.13   \n",
              "7                                                       Convert the time from GMT to EST   \n",
              "8  Create a pseudo-code algorithm to find the maximum number in a given list of numbers.   \n",
              "9                  Rewrite this English sentence into Spanish: The sun rises in the east   \n",
              "\n",
              "                                                                                                                                                           input  \\\n",
              "0                                                                                                                                              Theme: Friendship   \n",
              "1                                                                                                                                            Topic: Solar System   \n",
              "2  Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.   \n",
              "3                                                                                                                                 A flower garden in the morning   \n",
              "4                                                                                                         Sentence: Je veux aller √† la plage.\\nLanguage: Spanish   \n",
              "5                                                       Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.   \n",
              "6                                                                                                                                                                  \n",
              "7                                                                                                                                                  3:25 p.m. GMT   \n",
              "8                                                                                                                                                                  \n",
              "9                                                                                                                                                                  \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    output  \\\n",
              "0                                                                                                                                         Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                        The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                            Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.   \n",
              "3                                                                                                                                                                               The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Quiero ir a la playa.   \n",
              "5                                                                                                                                                                                                                                                              The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                         The difference between 11/80 and 0.13 is 0.0375.   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                       The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.   \n",
              "8  Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 El sol sale por el este.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                           generated_text  \n",
              "0  Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a  \n",
              "1                                                               Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this  \n",
              "2                          Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing  \n",
              "3                                                       Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister‚Äîor both. A night out, the weather improves as it did on Saturday.\\n\\nIt has  \n",
              "4                                                                                                                                                                                                                                                                                                                                            Translate a sentence from one language to another. Sentence: Je veux aller √† la plage.\\nLanguage: Spanish - drei\\nLanguage: French - f√©d√©rif  \n",
              "5                                                                               Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-  \n",
              "6                                                      Find the difference between 11/80 and 0.13 ¬†or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by  \n",
              "7                                                                                                                                                                                     Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard  \n",
              "8                                                                      Create a pseudo-code algorithm to find the maximum number in a given list of numbers. ¬†This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. ¬†The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%  \n",
              "9                                                     Rewrite this English sentence into Spanish: The sun rises in the east Óóí\\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69033958-ba76-4e87-9002-d0d3fba53eb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>generated_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Construct a story given a specific theme of choice.</td>\n",
              "      <td>Theme: Friendship</td>\n",
              "      <td>Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.</td>\n",
              "      <td>Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Retrieve a fact about a specific topic.</td>\n",
              "      <td>Topic: Solar System</td>\n",
              "      <td>The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.</td>\n",
              "      <td>Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way.</td>\n",
              "      <td>Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.</td>\n",
              "      <td>Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.</td>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Describe a scene to a blind person.</td>\n",
              "      <td>A flower garden in the morning</td>\n",
              "      <td>The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.</td>\n",
              "      <td>Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister‚Äîor both. A night out, the weather improves as it did on Saturday.\\n\\nIt has</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Translate a sentence from one language to another.</td>\n",
              "      <td>Sentence: Je veux aller √† la plage.\\nLanguage: Spanish</td>\n",
              "      <td>Quiero ir a la playa.</td>\n",
              "      <td>Translate a sentence from one language to another. Sentence: Je veux aller √† la plage.\\nLanguage: Spanish - drei\\nLanguage: French - f√©d√©rif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Given a scenario, decide which is the best advice.</td>\n",
              "      <td>Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.</td>\n",
              "      <td>The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.</td>\n",
              "      <td>Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Find the difference between 11/80 and 0.13</td>\n",
              "      <td></td>\n",
              "      <td>The difference between 11/80 and 0.13 is 0.0375.</td>\n",
              "      <td>Find the difference between 11/80 and 0.13 ¬†or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Convert the time from GMT to EST</td>\n",
              "      <td>3:25 p.m. GMT</td>\n",
              "      <td>The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.</td>\n",
              "      <td>Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers.</td>\n",
              "      <td></td>\n",
              "      <td>Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.</td>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers. ¬†This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. ¬†The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east</td>\n",
              "      <td></td>\n",
              "      <td>El sol sale por el este.</td>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east Óóí\\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69033958-ba76-4e87-9002-d0d3fba53eb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69033958-ba76-4e87-9002-d0d3fba53eb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69033958-ba76-4e87-9002-d0d3fba53eb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c86a98bd-d4a8-4f9d-a7af-7ae06507a8ab\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c86a98bd-d4a8-4f9d-a7af-7ae06507a8ab')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c86a98bd-d4a8-4f9d-a7af-7ae06507a8ab button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_gpt2",
              "summary": "{\n  \"name\": \"df_test_gpt2\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"Answer a trivia question related to this context.\",\n          \"What is a common use case for a machine learning algorithm?\",\n          \"Compare and contrast the characteristics of the desert and the jungle.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1169,\n        \"samples\": [\n          \"Subject: Artificial Intelligence\\nProblem: Making travel easier\",\n          \"Artificial intelligence will overtake humans in the next century.\",\n          \"Unease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2980,\n        \"samples\": [\n          \"If we don't reach our goals and dreams, we won't have it all, it won't be complete.\",\n          \"Foreign Direct Investment (FDI) is an investment made by a company or individual from one country into businesses located in another country. This type of investment can be made for various reasons, such as buying new assets, establishing joint ventures, or simply taking an ownership stake in the business. FDI can create jobs and can bring needed capital into the new host country. Additionally, it can result in improved economic opportunities and the sharing of technology, skills and knowledge between businesses.\",\n          \"The American media generally portrays politics in a negative light. News coverage is often focused on the negative aspects of politics and the political process. It often ignores the positive impacts of policy decisions and tends to distort the actual picture of politics \\u2013 often displaying it as a circus of corruption and dysfunction. This depiction of politics can be damaging, as it encourages citizens to think of politicians and those in power as adversaries rather than potential partners or problem solvers.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Create a pseudo-code algorithm to find the maximum number in a given list of numbers. \\u00a0This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. \\u00a0The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%\",\n          \"Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this\",\n          \"Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \\\"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\\\"\\nOr suppose you're writing in, \\\"It's only $9.12 a week, and I can't find any work that's not more reasonable\\\", and that's a half-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avalia√ß√£o do Modelo GPT2-Small\n",
        "\n",
        "* Observa√ß√µes: O modelo apresentou dificuldades em interpretar as instru√ß√µes do dataset escolhido, gerando respostas inconsistentes.\n"
      ],
      "metadata": {
        "id": "fRSHs1PnVa-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melhorias Propostas\n",
        "\n",
        "1.  Divis√£o estratificada dos datasets (classifica√ß√£o ou clusteriza√ß√£o)\n",
        "  - A escolha aleat√≥ria das linhas para os datasets de treino e teste √© uma abordagem v√°lida, mas pode ser interessante explorar outras estrat√©gias, como a divis√£o estratificada, para garantir que ambos os datasets representem adequadamente a distribui√ß√£o dos dados originais.\n",
        "2.  Explora√ß√£o de modelos maiores (GPT2-Medium, GPT2-Large)\n",
        "  - O GPT2-Small pode ser limitado para tarefas complexas. Podemos considerar em explorar modelos maiores, como o GPT2-Medium ou GPT2-Large, para obter melhores resultados. No entanto, modelos maiores exigem mais recursos computacionais.\n",
        "3.  Fine-tuning do modelo com o dataset de treino\n",
        "  - Ajustar o modelo GPT2-Small com dataset de treinamento pode melhorar significativamente o desempenho. O fine-tuning permite que o modelo se adapte √†s caracter√≠sticas espec√≠ficas dos seus dados. (Esta abordagem foi selecionada para melhorar a resposta do modelo maix abaixo).\n",
        "4.  Aprimoramento da formula√ß√£o dos prompts\n",
        "  - O ideal seria incluir as informa√ß√µes prim√°rias da coluna 'text' do dataset. No entanto, essa coluna foi removida, pois estava gerando complica√ß√µes no treinamento do modelo e enviesando o output, que retornava exatamente o que a pr√≥pria coluna sugeria. Normalmente, datasets n√£o possuem esse tipo de informa√ß√£o; essa coluna, em espec√≠fico, parece ter sido inclu√≠da apenas para fins de estudo."
      ],
      "metadata": {
        "id": "WtMX0SKsWyD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 2"
      ],
      "metadata": {
        "id": "pzM7dA3SGuRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-Tuning"
      ],
      "metadata": {
        "id": "RX7SvlL-G2_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"text\": f\"Instruction: {example['instruction']}\\nInput: {example['input']}\\nOutput: {example['output']}\"\n",
        "    }\n",
        "\n",
        "dataset = dataset_train.map(format_prompt)"
      ],
      "metadata": {
        "id": "84BqSvT1Bc3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0b975953b3ac44439b14592fb93ce1f6",
            "c8e00dc9a7734527821244f6b248dfce",
            "88ab70fc63104b9fbf2f49638b8f62a5",
            "8a660597753444908970e55988eb2539",
            "a747abb624b94c89aa363a632d10747f",
            "f9a0177277584442ab57d096b8d1c683",
            "43a9fb5c50194b389b261742e7c7a5a5",
            "73e900c6725a4acaba0d38943bf8d695",
            "60d6116253ab436d89960f046e049c19",
            "7fea0c2448ae4a84a3aae59edb668e05",
            "04c48443509f4f9da5cc8df0286d57c1"
          ]
        },
        "outputId": "79c97779-edfe-48d4-b5ef-8cb5cd998d1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b975953b3ac44439b14592fb93ce1f6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"ComCom/gpt2-small\")"
      ],
      "metadata": {
        "id": "agFpe01BJAxW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokeniza√ß√£o do dataset"
      ],
      "metadata": {
        "id": "TqNSAvSR5qN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"ComCom/gpt2-small\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    text_tokenized = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    output_tokenized = tokenizer(examples[\"output\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "    return {\n",
        "        \"input_ids\": text_tokenized[\"input_ids\"],\n",
        "        \"attention_mask\": text_tokenized[\"attention_mask\"],\n",
        "        \"labels\": output_tokenized[\"input_ids\"],\n",
        "    }\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "uRVperBvA2eu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "36aa6d2ac3ed4160a1382ba850bd55c4",
            "ffbf064e87ce4e2e9327ab673339fd07",
            "ac86385d15ee4b17b1a7ff3347a00e58",
            "b4c9cf093c8141a1b3fd766284cd3344",
            "6dddf0c87b7941308ac6d24ca540a953",
            "b60949fe3dd641489f36f8c1ff35faf8",
            "4392f4187cbd496bb96f9fb0b3bd55ca",
            "2fc275d328244e70981e2877817ca4a9",
            "0fbf02a169274006b29f1d61d5a23130",
            "3d04a4a8fa794654937c5cb8f03aac04",
            "34af15605cef41d4aaa0c79bfb266862"
          ]
        },
        "outputId": "a1aafce8-3903-40c1-d872-f1d749e88402"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36aa6d2ac3ed4160a1382ba850bd55c4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepara√ß√£o dos dados para treino e test\n",
        "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "train_dataset = tokenized_datasets.shuffle(seed=456).select(range(2500))\n",
        "eval_dataset = tokenized_datasets.shuffle(seed=456).select(range(len(tokenized_datasets) - 300, len(tokenized_datasets)))"
      ],
      "metadata": {
        "id": "OC8QH_LF_zjJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O uso do DataCollatorForLanguageModeling √© adequado para tarefas de gera√ß√£o de texto.\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "GxUcbUIvFYBR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        "    run_name=\"my-gpt2-test_dataset-run\",\n",
        "    eval_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "wandb.login(key=userdata.get('WANDB_API_KEY'))\n"
      ],
      "metadata": {
        "id": "BQQXc0caCB9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29ff4d3-c7e0-41c7-a0d5-d11f16eb1dc6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoukyto\u001b[0m (\u001b[33mhoukyto-particular\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento do modelo"
      ],
      "metadata": {
        "id": "7nB98Ef7FeIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() # Aplicando os argumentos e treinando o modelo\n",
        "\n",
        "# Tabela summario de m√©tricas de treinamento\n",
        "metrics = {\n",
        "    \"train_runtime\": trainer.state.log_history[-1][\"train_runtime\"],\n",
        "    \"train_samples_per_second\": trainer.state.log_history[-1][\"train_samples_per_second\"],\n",
        "    \"train_steps_per_second\": trainer.state.log_history[-1][\"train_steps_per_second\"],\n",
        "    \"train_loss\": trainer.state.log_history[-1][\"train_loss\"],\n",
        "    \"epoch\": trainer.state.log_history[-1][\"epoch\"]\n",
        "}\n",
        "\n",
        "df_train_output = pd.DataFrame([metrics])\n",
        "\n",
        "df_train_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "T7bra8T_Gucq",
        "outputId": "db264492-de70-4b2e-bba6-0e5f92182eb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250503_144459-33zcv4mp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/houkyto-particular/huggingface/runs/33zcv4mp' target=\"_blank\">my-gpt2-test_dataset-run</a></strong> to <a href='https://wandb.ai/houkyto-particular/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/houkyto-particular/huggingface' target=\"_blank\">https://wandb.ai/houkyto-particular/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/houkyto-particular/huggingface/runs/33zcv4mp' target=\"_blank\">https://wandb.ai/houkyto-particular/huggingface/runs/33zcv4mp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3130/3130 31:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.247200</td>\n",
              "      <td>2.162754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.043700</td>\n",
              "      <td>2.129907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.997700</td>\n",
              "      <td>2.125949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.980400</td>\n",
              "      <td>2.128057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.845200</td>\n",
              "      <td>2.132505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.807300</td>\n",
              "      <td>2.140540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.826000</td>\n",
              "      <td>2.145466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.688600</td>\n",
              "      <td>2.155646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.699200</td>\n",
              "      <td>2.158149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.571800</td>\n",
              "      <td>2.160263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
              "0      1887.5693                    13.245                   1.658   \n",
              "\n",
              "   train_loss  epoch  \n",
              "0    1.879895   10.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aed4475-2eb7-49c6-a553-58bd6cc40668\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_runtime</th>\n",
              "      <th>train_samples_per_second</th>\n",
              "      <th>train_steps_per_second</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1887.5693</td>\n",
              "      <td>13.245</td>\n",
              "      <td>1.658</td>\n",
              "      <td>1.879895</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aed4475-2eb7-49c6-a553-58bd6cc40668')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6aed4475-2eb7-49c6-a553-58bd6cc40668 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6aed4475-2eb7-49c6-a553-58bd6cc40668');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2d3d1281-9093-4005-95f7-d3a23a4a74a0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train_output')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d3d1281-9093-4005-95f7-d3a23a4a74a0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train_output');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_output",
              "summary": "{\n  \"name\": \"df_train_output\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"train_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1887.5693,\n        \"max\": 1887.5693,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1887.5693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13.245,\n        \"max\": 13.245,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13.245\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.658,\n        \"max\": 1.658,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.8798946935147904,\n        \"max\": 1.8798946935147904,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.8798946935147904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 10.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa, o modelo GPT2-Small foi ajustado (fine-tuning) utilizando o dataset de treino. O objetivo foi adaptar o modelo √†s caracter√≠sticas espec√≠ficas dos dados, melhorando seu desempenho na gera√ß√£o de texto com base nas instru√ß√µes fornecidas.\n",
        "\n",
        "#### Etapas Realizadas\n",
        "\n",
        "1.  **Formata√ß√£o dos Prompts:**\n",
        "    * As instru√ß√µes, entradas e sa√≠das do dataset de treino foram formatadas em um formato de prompt adequado para o modelo.\n",
        "    * A fun√ß√£o `format_prompt` foi utilizada para combinar essas informa√ß√µes em um texto √∫nico.\n",
        "\n",
        "2.  **Tokeniza√ß√£o dos Dados:**\n",
        "    * O dataset de treino foi tokenizado utilizando o tokenizador do GPT2-Small.\n",
        "    * A fun√ß√£o `tokenize_function` converteu os textos formatados em sequ√™ncias de tokens, prontas para serem processadas pelo modelo.\n",
        "    * O par√¢metro `max_length` foi ajustado para 256, permitindo sequ√™ncias de texto mais longas. (Tamb√©m pode ser ajustado para o tamanho m√©dio das sequ√™ncias do seu dataset para definir um max_length otimizado)\n",
        "\n",
        "3.  **Prepara√ß√£o dos Datasets de Treino e Avalia√ß√£o:**\n",
        "    * O dataset tokenizado foi dividido em conjuntos de treino e avalia√ß√£o.\n",
        "    * O `DataCollatorForLanguageModeling` foi utilizado para criar lotes de dados para o treinamento.\n",
        "\n",
        "4.  **Treinamento do Modelo:**\n",
        "    * O `Trainer` da biblioteca `transformers` foi utilizado para ajustar o modelo GPT2-Small.\n",
        "    * Os hiperpar√¢metros de treinamento foram definidos nos `TrainingArguments`, incluindo a taxa de aprendizado, o n√∫mero de √©pocas e o tamanho do lote.\n",
        "    * O par√¢metro `eval_strategy` foi definido como `'epoch'`, permitindo a avalia√ß√£o do modelo ao final de cada √©poca.\n",
        "    * O par√¢metro `save_strategy` foi definido como `'epoch'`, permitindo gravar o modelo em cada √©poca.    \n",
        "    * O par√¢metro `load_best_model_at_end` foi adicionado para salvar o melhor modelo com base na m√©trica de avalia√ß√£o.\n",
        "    * O monitoramento do treinamento foi realizado utilizando o `wandb`.\n",
        "\n",
        "5.  **Avalia√ß√£o do Treinamento:**\n",
        "    * As m√©tricas de treinamento foram coletadas e exibidas em um DataFrame, incluindo o tempo de treinamento, a perda e a √©poca.\n",
        "\n",
        "### An√°lises e Melhorias\n",
        "\n",
        "* O ajuste dos hiperpar√¢metros, como o n√∫mero de √©pocas `epochs` e o tamanho do lote, pode ter um impacto significativo no desempenho do modelo. Pode-se explorar diferentes valores para esses hiperpar√¢metros, equilibrando o custo computacional e a perforance do treinamento.\n",
        "* A avalia√ß√£o durante o treinamento, permitida pelo par√¢metro `eval_strategy`, ajuda a monitorar o desempenho do modelo e evitar o overfitting.\n",
        "* O salvamento do melhor modelo, ativado pelo par√¢metro `load_best_model_at_end`, garante que o modelo com o melhor desempenho seja utilizado.\n",
        "* Aumentar o `max_length` na tokeniza√ß√£o permite que o modelo processe sequ√™ncias de texto mais longas, preservando mais informa√ß√µes.\n",
        "* O uso de t√©cnicas de Parameter-Efficient Fine-Tuning (PEFT), como LoRA, pode reduzir o consumo de mem√≥ria durante o treinamento.\n"
      ],
      "metadata": {
        "id": "EyMbv0JQYsGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 3"
      ],
      "metadata": {
        "id": "DYVdWiG30ylM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Realizando o teste ap√≥s o ajuste do modelo"
      ],
      "metadata": {
        "id": "XVgTav5pBm9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(instruction, model, tokenizer, seed=456):\n",
        "    prompt = f\"Instruction: {instruction}\\nOutput:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=128, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    generated_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_output.split(\"Output:\")[1].strip()\n",
        "\n",
        "test_example = dataset[9]\n",
        "instruction = test_example['instruction']+' '+test_example['input']\n",
        "input = test_example['input']\n",
        "output = test_example['output']\n",
        "generated_output = generate_output(instruction, model, tokenizer)\n",
        "print(f\"Instruction Test: {instruction}\")\n",
        "print(f\"Input Test: {input}\")\n",
        "print(f\"Expected Output: {output}\")\n",
        "print(f\"Generated Output: {generated_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoNWZYG__dM5",
        "outputId": "e98d05b4-515a-4e8d-8ea1-8f43d7737fe4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction Test: Evaluate this sentence for spelling and grammar mistakes He finnished his meal and left the resturant\n",
            "Input Test: He finnished his meal and left the resturant\n",
            "Expected Output: He finished his meal and left the restaurant.\n",
            "Generated Output: He finished his dinner and departed the dining room. He was greeted by a group of people, including a woman who was wearing a bright red dress and a blue dress. She smiled and waved goodbye to him.\n",
            "Input: \n",
            "\n",
            "She smiled back and said, \"Good evening, everyone.\"\n",
            "   She walked to the table and sat down.  Her eyes were wide and she looked up at him with a smile. Her heart was pounding and her eyes filled with tears. The woman smiled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_example = dataset[7]\n",
        "instruction = test_example['instruction']+ ' '+test_example['input']\n",
        "input = test_example['input']\n",
        "output = test_example['output']\n",
        "generated_output = generate_output(instruction, model, tokenizer)\n",
        "print(f\"Instruction Test: {instruction}\")\n",
        "print(f\"Input Test: {input}\")\n",
        "print(f\"Expected Output: {output}\")\n",
        "print(f\"Generated Output: {generated_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMn_O8aI-wQx",
        "outputId": "16ffe1d8-3c4e-4cf8-c80e-9aafedfb0751"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction Test: Write a short story in third person narration about a protagonist who has to make an important career decision. \n",
            "Input Test: \n",
            "Expected Output: John was at a crossroads in his life. He had just graduated college and was now facing the big decision of what career to pursue. After much deliberation, he decided that he wanted to be an accountant and help the financially disadvantaged. He had always been good with numbers and enjoyed seeing the tangible results of his work. \n",
            "\n",
            "John enrolled in accounting courses and initially found it quite challenging. He had to learn multiple systems and regulations quickly, but he worked hard and eventually excelled in his studies. After a few years, John started working at an accounting firm in his city. He was eager to put his knowledge of taxes and accounting to use in a real-world setting.\n",
            "\n",
            "John loved his job, as it let him express his creativity in finding strategies to save his clients money. After a few years at the firm, he became a senior accountant and was asked to manage bigger and more challenging cases. He was now a respected figure in the financial industry, but he still remembers when he was just a recent college graduate, unsure of the direction in which his life would take him.\n",
            "Generated Output: The protagonist is a young man who is struggling to find his way in life. He is determined to pursue his dreams and pursue a career in the field of medicine. But he is also determined not to let his past lead him to failure. His life is filled with obstacles and struggles, and he must make a difficult decision to reach his goal.\n",
            "\n",
            "The story follows the protagonist as he struggles to overcome his struggles and find a way to live a fulfilling life in a world that is full of obstacles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Incluindo a nova coluna no data frame: df_test_gpt2\n",
        "\n"
      ],
      "metadata": {
        "id": "IXubup5KFLBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_gpt2['text_generated_new'] = None\n",
        "\n",
        "for index in range(10):\n",
        "  instruction = df_test_gpt2.loc[index, 'instruction']\n",
        "  input = df_test_gpt2.loc[index, 'input']\n",
        "  if pd.notnull(input):\n",
        "    instruction_with_input = instruction + ' ' + input\n",
        "    generated_output_new = generate_output(instruction_with_input, model, tokenizer)\n",
        "  else:\n",
        "    generated_output_new = generate_output(instruction, model, tokenizer)\n",
        "\n",
        "  df_test_gpt2.loc[index, 'text_generated_new'] = generated_output_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Q7JMtinlMI",
        "outputId": "30619d29-4bc2-4bb1-ae1b-d39768428a52"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_gpt2.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CyLcSPSIORRF",
        "outputId": "942097fb-ad40-4940-ba82-aa796ea3fa21"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             instruction  \\\n",
              "0                                    Construct a story given a specific theme of choice.   \n",
              "1                                                Retrieve a fact about a specific topic.   \n",
              "2                   Rearrange a paragraph to make it read in an orderly and logical way.   \n",
              "3                                                    Describe a scene to a blind person.   \n",
              "4                                     Translate a sentence from one language to another.   \n",
              "5                                     Given a scenario, decide which is the best advice.   \n",
              "6                                             Find the difference between 11/80 and 0.13   \n",
              "7                                                       Convert the time from GMT to EST   \n",
              "8  Create a pseudo-code algorithm to find the maximum number in a given list of numbers.   \n",
              "9                  Rewrite this English sentence into Spanish: The sun rises in the east   \n",
              "\n",
              "                                                                                                                                                           input  \\\n",
              "0                                                                                                                                              Theme: Friendship   \n",
              "1                                                                                                                                            Topic: Solar System   \n",
              "2  Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.   \n",
              "3                                                                                                                                 A flower garden in the morning   \n",
              "4                                                                                                         Sentence: Je veux aller √† la plage.\\nLanguage: Spanish   \n",
              "5                                                       Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.   \n",
              "6                                                                                                                                                                  \n",
              "7                                                                                                                                                  3:25 p.m. GMT   \n",
              "8                                                                                                                                                                  \n",
              "9                                                                                                                                                                  \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    output  \\\n",
              "0                                                                                                                                         Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                        The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                            Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.   \n",
              "3                                                                                                                                                                               The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Quiero ir a la playa.   \n",
              "5                                                                                                                                                                                                                                                              The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                         The difference between 11/80 and 0.13 is 0.0375.   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                       The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.   \n",
              "8  Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 El sol sale por el este.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                           generated_text  \\\n",
              "0  Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a   \n",
              "1                                                               Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this   \n",
              "2                          Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing   \n",
              "3                                                       Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister‚Äîor both. A night out, the weather improves as it did on Saturday.\\n\\nIt has   \n",
              "4                                                                                                                                                                                                                                                                                                                                            Translate a sentence from one language to another. Sentence: Je veux aller √† la plage.\\nLanguage: Spanish - drei\\nLanguage: French - f√©d√©rif   \n",
              "5                                                                               Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-   \n",
              "6                                                      Find the difference between 11/80 and 0.13 ¬†or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by   \n",
              "7                                                                                                                                                                                     Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard   \n",
              "8                                                                      Create a pseudo-code algorithm to find the maximum number in a given list of numbers. ¬†This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. ¬†The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%   \n",
              "9                                                     Rewrite this English sentence into Spanish: The sun rises in the east Óóí\\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text_generated_new  \n",
              "0  The protagonist is a young man who is fascinated by the beauty of nature. He is determined to find a way to make it all the more special.\\n\\nThe protagonist's journey begins with a journey to the edge of the world, where he meets a mysterious stranger. The stranger is an old man named John. John is the only person who can remember the past and the present, and he is able to remember everything that happened in the future. As John grows up, he discovers that he can use his memories to create a better future for  \n",
              "1                              The Solar system is a system of planets orbiting the Sun. It is composed of three main planets, Mercury, Uranus and Neptune. Mercury orbits the Earth at a distance of about 1,200 light-years. Uranium orbits Saturn at an angle of approximately 1.5 degrees. Neptune orbits Jupiter at the same angle. The Sun is the only planet in the Solar systems that is not surrounded by matter.\\n\\nThe Sun orbits its axis of rotation at about 7.8 degrees per year. Its distance from the sun is about 5,  \n",
              "2                                                                                                                      The next steps to be taken are to identify patterns in data and to use the visualizations to better understand the underlying patterns. The data should be analyzed and analyzed to determine the best way to interpret the results. Finally, the user should have the opportunity to interact with the app and interactivity should improve. This is a great way for Alexa to help users understand their data  \n",
              "3                                                   The scene in question is a flower growing in a garden. The flower is surrounded by a large, green, and yellow flower. It is blooming in mid-summer and is usually a beautiful sight. In the evening, the flower blooms in an open field, surrounded on all sides by trees and bushes. On the day, it is in full bloom and bloomes in late summer. During the summer, when the sun is shining brightly, flowers are bloating in open fields and in summertime, they are usually blo  \n",
              "4                                                                                                                                                                                                                                              The plages were a kind of portable furniture. They were made of wood, and were usually made to last for years. Je vous avez un pla√Æt, le plager de la Plage de l'Avant-Garde. \\n\\nJe voulez un peuvent de plagiarisme, mais le monde de leurs plagers de Plagieux. Il est un m√™me de m√©  \n",
              "5                                                                    The best way to plan for a job in the new state is to stay in touch with your new employer and make sure that you have the necessary skills and experience to make the decision. Additionally, you should consider the benefits of staying in contact with the company and the potential benefits that come with staying connected to them. Finally, make a plan to get to know your current employer better and to ensure that they have a good understanding of  \n",
              "6                                                          11.83 is the average of the 11th and 12th centuries. It is equivalent to the 12 th and 13 th centuries, respectively. The difference is that 11 is shorter than 0, whereas 12 is longer than 11, while 13 is equal to 0 and 11 are equal. Therefore, 11 has a shorter average than 12, and it is therefore equivalent.\\n\\n12.14 is a measure of how long a given period is. This is calculated by dividing the length of a period by the number of years. For example, if a  \n",
              "7                                                                                                                                                  The time to arrive at the airport is 3 p, 19:00. The airport will be open from 9:30 a.M. to 5:45 p., and will open at 5 p ET.\\nInput: \\n\\nThe time for arriving at airport at 3 pm is 9 p EST. This means that the arrival time will start at 9 pm and end at 11:59 pm. Therefore, the estimated arrival times for the following airports are:\\nTokyo, Tokyo, and Tokyo-Mitsubishi.  \n",
              "8                                                                                                                                                                                                                           1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\nInput  \n",
              "9                                                     He rises with the sun in his sky.\\n\\nThe sun is rising in a bright and beautiful sky, shining like a beacon of light. He is the star of the night, and the stars are the light of day. The stars shine like stars, illuminating the world and making it brighter and brighter. They are like the rays of sunlight, making the sky brighter, brighter than ever before. It is a beautiful day, filled with stars and shadows, but it is also a time of peace and joy.  The sky is  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd7e8602-09ec-448d-b866-e164abeb6ec6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>generated_text</th>\n",
              "      <th>text_generated_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Construct a story given a specific theme of choice.</td>\n",
              "      <td>Theme: Friendship</td>\n",
              "      <td>Once upon a time, there was a young boy who had no friends. That is, until one day when he met a friendly dog. The boy was skeptical at first, but eventually the two became inseparable. They would play in the park, share stories and adventures, and explore the outdoors together. The boy learned the importance of friendship and was never lonely again.</td>\n",
              "      <td>Construct a story given a specific theme of choice. Theme: Friendship and Magic\\n\\nNote that this is not a universal design principle, but an application of one theme: Friendship and Magic. What this means is that for any one story a theme may work on multiple stories, whether that is one specific piece of music, or more or less, and whether those themes overlap. The theme of choice here relates to the content of the story.\\n\\nIn our example, we show a story about a</td>\n",
              "      <td>The protagonist is a young man who is fascinated by the beauty of nature. He is determined to find a way to make it all the more special.\\n\\nThe protagonist's journey begins with a journey to the edge of the world, where he meets a mysterious stranger. The stranger is an old man named John. John is the only person who can remember the past and the present, and he is able to remember everything that happened in the future. As John grows up, he discovers that he can use his memories to create a better future for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Retrieve a fact about a specific topic.</td>\n",
              "      <td>Topic: Solar System</td>\n",
              "      <td>The Solar System consists of the sun and its planetary system of eight planets, 174 moons, and the dwarf planets.</td>\n",
              "      <td>Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this</td>\n",
              "      <td>The Solar system is a system of planets orbiting the Sun. It is composed of three main planets, Mercury, Uranus and Neptune. Mercury orbits the Earth at a distance of about 1,200 light-years. Uranium orbits Saturn at an angle of approximately 1.5 degrees. Neptune orbits Jupiter at the same angle. The Sun is the only planet in the Solar systems that is not surrounded by matter.\\n\\nThe Sun orbits its axis of rotation at about 7.8 degrees per year. Its distance from the sun is about 5,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way.</td>\n",
              "      <td>Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take.</td>\n",
              "      <td>Alexa observed the trends in the input data from the sensors and thought of the next step to take. She visualized the patterns on the screen.</td>\n",
              "      <td>Rearrange a paragraph to make it read in an orderly and logical way. Alexa took the data from the sensors and visualized the patterns on the screen. She observed the trends in the input data, thinking of the next step to take. Then she did it again, with Alexa running a visual-scanning tool to keep track of the changes in the data.\\n\\nShe wanted to do something about the color-changing patterns on our home screen.\\n\\nAlexa said the next thing</td>\n",
              "      <td>The next steps to be taken are to identify patterns in data and to use the visualizations to better understand the underlying patterns. The data should be analyzed and analyzed to determine the best way to interpret the results. Finally, the user should have the opportunity to interact with the app and interactivity should improve. This is a great way for Alexa to help users understand their data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Describe a scene to a blind person.</td>\n",
              "      <td>A flower garden in the morning</td>\n",
              "      <td>The morning air is cool and crisp. The sun is just peeking over the horizon, sending a wash of golden light over the flower garden. You can smell the sweet scent of the flowers and hear the gentle buzzing of the bees pollinating. A soft breeze rustles their petals and rustic wooden fence ties the garden together.</td>\n",
              "      <td>Describe a scene to a blind person. A flower garden in the morning and a blackboard and a typewriter in the evening. The girl's name is Jane, it was born on March 14. An afternoon call to the hospital. A visit to the doctor. An hour of silence at a local church. A long afternoon conversation to an old friend. The death of a friend's sister‚Äîor both. A night out, the weather improves as it did on Saturday.\\n\\nIt has</td>\n",
              "      <td>The scene in question is a flower growing in a garden. The flower is surrounded by a large, green, and yellow flower. It is blooming in mid-summer and is usually a beautiful sight. In the evening, the flower blooms in an open field, surrounded on all sides by trees and bushes. On the day, it is in full bloom and bloomes in late summer. During the summer, when the sun is shining brightly, flowers are bloating in open fields and in summertime, they are usually blo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Translate a sentence from one language to another.</td>\n",
              "      <td>Sentence: Je veux aller √† la plage.\\nLanguage: Spanish</td>\n",
              "      <td>Quiero ir a la playa.</td>\n",
              "      <td>Translate a sentence from one language to another. Sentence: Je veux aller √† la plage.\\nLanguage: Spanish - drei\\nLanguage: French - f√©d√©rif</td>\n",
              "      <td>The plages were a kind of portable furniture. They were made of wood, and were usually made to last for years. Je vous avez un pla√Æt, le plager de la Plage de l'Avant-Garde. \\n\\nJe voulez un peuvent de plagiarisme, mais le monde de leurs plagers de Plagieux. Il est un m√™me de m√©</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Given a scenario, decide which is the best advice.</td>\n",
              "      <td>Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state.</td>\n",
              "      <td>The best advice is to weigh the pros and cons of taking the new job. Consider the financial benefits, the impact it will have on your lifestyle, the potential for professional development, and any personal factors that may be impacted.</td>\n",
              "      <td>Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\"\\nOr suppose you're writing in, \"It's only $9.12 a week, and I can't find any work that's not more reasonable\", and that's a half-</td>\n",
              "      <td>The best way to plan for a job in the new state is to stay in touch with your new employer and make sure that you have the necessary skills and experience to make the decision. Additionally, you should consider the benefits of staying in contact with the company and the potential benefits that come with staying connected to them. Finally, make a plan to get to know your current employer better and to ensure that they have a good understanding of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Find the difference between 11/80 and 0.13</td>\n",
              "      <td></td>\n",
              "      <td>The difference between 11/80 and 0.13 is 0.0375.</td>\n",
              "      <td>Find the difference between 11/80 and 0.13 ¬†or 0.06 is a great and reasonable estimate, if your car is not going to get you a big mileage upgrade.\\nHere's what I did: I set all my cars apart from my other vehicles by adjusting their VINs. Then I looked at their driving style and then the car class of both their other vehicles and their driving style. Then I took the \"average\" standard for both. Then I divided it by</td>\n",
              "      <td>11.83 is the average of the 11th and 12th centuries. It is equivalent to the 12 th and 13 th centuries, respectively. The difference is that 11 is shorter than 0, whereas 12 is longer than 11, while 13 is equal to 0 and 11 are equal. Therefore, 11 has a shorter average than 12, and it is therefore equivalent.\\n\\n12.14 is a measure of how long a given period is. This is calculated by dividing the length of a period by the number of years. For example, if a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Convert the time from GMT to EST</td>\n",
              "      <td>3:25 p.m. GMT</td>\n",
              "      <td>The time 3:25 p.m. GMT is equal to 11:25 a.m. EST.</td>\n",
              "      <td>Convert the time from GMT to EST 3:25 p.m. GMT (2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time)\\n\\n(2:25 p.m. Eastern Standard Time, 2:25 p.m. Eastern Standard Time) Convert the time from GMT to EST 3:30 p.m. GMT (2:30 p.m. Eastern Standard Time, 2:30 p.m. Eastern Standard</td>\n",
              "      <td>The time to arrive at the airport is 3 p, 19:00. The airport will be open from 9:30 a.M. to 5:45 p., and will open at 5 p ET.\\nInput: \\n\\nThe time for arriving at airport at 3 pm is 9 p EST. This means that the arrival time will start at 9 pm and end at 11:59 pm. Therefore, the estimated arrival times for the following airports are:\\nTokyo, Tokyo, and Tokyo-Mitsubishi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers.</td>\n",
              "      <td></td>\n",
              "      <td>Algorithm:\\n1. Create a new list to store the maximum numbers.\\n2. Start a for loop with index i for the given list of numbers.\\n3. Compare the current number with other numbers in the list.\\n4. If the current number is greater, store it in the new list.\\n5. If the current number is lesser, do nothing.\\n6. After the for loop is complete, the new list contains the maximum numbers.\\n7. Find the maximum of the maximum numbers and store it in a new variable.\\n8. Return the new variable.</td>\n",
              "      <td>Create a pseudo-code algorithm to find the maximum number in a given list of numbers. ¬†This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. ¬†The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%</td>\n",
              "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\nInput</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east</td>\n",
              "      <td></td>\n",
              "      <td>El sol sale por el este.</td>\n",
              "      <td>Rewrite this English sentence into Spanish: The sun rises in the east Óóí\\n\\nHere's another idea: If you had to come down in America, what is your daily dose of the new life? The Sun will be there. What the hell does that take in the morning? It takes in life, of course - but you're just now discovering that you have plenty. But you need a little extra space to be able to take yourself to the next level. It takes time</td>\n",
              "      <td>He rises with the sun in his sky.\\n\\nThe sun is rising in a bright and beautiful sky, shining like a beacon of light. He is the star of the night, and the stars are the light of day. The stars shine like stars, illuminating the world and making it brighter and brighter. They are like the rays of sunlight, making the sky brighter, brighter than ever before. It is a beautiful day, filled with stars and shadows, but it is also a time of peace and joy.  The sky is</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd7e8602-09ec-448d-b866-e164abeb6ec6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd7e8602-09ec-448d-b866-e164abeb6ec6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd7e8602-09ec-448d-b866-e164abeb6ec6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-52bdfcab-1d3a-477b-bf6a-6e185f67d904\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52bdfcab-1d3a-477b-bf6a-6e185f67d904')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-52bdfcab-1d3a-477b-bf6a-6e185f67d904 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_gpt2",
              "summary": "{\n  \"name\": \"df_test_gpt2\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"Answer a trivia question related to this context.\",\n          \"What is a common use case for a machine learning algorithm?\",\n          \"Compare and contrast the characteristics of the desert and the jungle.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1169,\n        \"samples\": [\n          \"Subject: Artificial Intelligence\\nProblem: Making travel easier\",\n          \"Artificial intelligence will overtake humans in the next century.\",\n          \"Unease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2980,\n        \"samples\": [\n          \"If we don't reach our goals and dreams, we won't have it all, it won't be complete.\",\n          \"Foreign Direct Investment (FDI) is an investment made by a company or individual from one country into businesses located in another country. This type of investment can be made for various reasons, such as buying new assets, establishing joint ventures, or simply taking an ownership stake in the business. FDI can create jobs and can bring needed capital into the new host country. Additionally, it can result in improved economic opportunities and the sharing of technology, skills and knowledge between businesses.\",\n          \"The American media generally portrays politics in a negative light. News coverage is often focused on the negative aspects of politics and the political process. It often ignores the positive impacts of policy decisions and tends to distort the actual picture of politics \\u2013 often displaying it as a circus of corruption and dysfunction. This depiction of politics can be damaging, as it encourages citizens to think of politicians and those in power as adversaries rather than potential partners or problem solvers.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Create a pseudo-code algorithm to find the maximum number in a given list of numbers. \\u00a0This uses a combination of a list of strings, including the value of the first keyword, and a list of strings, including the value of the second keyword, to perform an analysis of the strings. \\u00a0The result of this algorithm can be described as a function like this:\\ndef do_search(item, index=0): print('%s, %d-%d '%\",\n          \"Retrieve a fact about a specific topic. Topic: Solar System-forming star An image:\\n\\nThis example is a reference of the NASA/ESA Hubble Space Telescope. This image is available here:\\n\\nNASA/ESA Hubble Space Telescope / NASA/JPL-Caltech/Shiu-Hsi\\n\\nIt will take you a while unless you're willing to wait longer and you want to move this image towards you. On the contrary, we hope you enjoy your time on this\",\n          \"Given a scenario, decide which is the best advice. Scenario:\\nA friend is considering taking a new job that pays more money, but it's in a different state. He's thinking \\\"How can I make the minimum wage that is reasonable, but pay more? A small part of that fee?\\\"\\nOr suppose you're writing in, \\\"It's only $9.12 a week, and I can't find any work that's not more reasonable\\\", and that's a half-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_generated_new\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\\nInput\",\n          \"The Solar system is a system of planets orbiting the Sun. It is composed of three main planets, Mercury, Uranus and Neptune. Mercury orbits the Earth at a distance of about 1,200 light-years. Uranium orbits Saturn at an angle of approximately 1.5 degrees. Neptune orbits Jupiter at the same angle. The Sun is the only planet in the Solar systems that is not surrounded by matter.\\n\\nThe Sun orbits its axis of rotation at about 7.8 degrees per year. Its distance from the sun is about 5,\",\n          \"The best way to plan for a job in the new state is to stay in touch with your new employer and make sure that you have the necessary skills and experience to make the decision. Additionally, you should consider the benefits of staying in contact with the company and the potential benefits that come with staying connected to them. Finally, make a plan to get to know your current employer better and to ensure that they have a good understanding of\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Avaliando a qualidade do resultado ap√≥s o treinamento do modelo:\n",
        "\n",
        "Ap√≥s treinar o modelo com o dataset vimos que ele conseguiu adptar um pouco melhor as repostas, por√©m ainda √© necess√°rio alguns ajustes.\n",
        "Como alternativa alguns par√¢metros podem ser ajustados para retreinar o modelo, por√©m sem prejudicar no custo computacional."
      ],
      "metadata": {
        "id": "3WC1Qn89WgnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo GPT2-Small ajustado na Etapa 2 foi utilizado para gerar respostas/outputs para as instru√ß√µes do dataset de teste. O objetivo foi avaliar o impacto do fine-tuning no desempenho do modelo.\n",
        "\n",
        "* An√°lises:\n",
        "\n",
        "1.  **Gera√ß√£o de Respostas com o Modelo Ajustado:**\n",
        "\n",
        "    * A fun√ß√£o `generate_output`, que utiliza o modelo ajustado para gerar respostas com base nas instru√ß√µes fornecidas. A fun√ß√£o tokeniza as instru√ß√µes, gera as respostas e as decodifica. Em seguida, o c√≥digo itera sobre os exemplos do dataset de teste, gera as respostas e as armazena em uma nova coluna do DataFrame `df_test_gpt2`.\n",
        "    * **An√°lise:** Ao comparar as respostas geradas pelo modelo ajustado com as respostas esperadas, observamos uma melhora na qualidade das respostas em rela√ß√£o √† Etapa 1. No entanto, ainda h√° espa√ßo para otimiza√ß√£o.\n",
        "\n",
        "2.  **Avalia√ß√£o da Qualidade do Resultado:**\n",
        "\n",
        "    * A avalia√ß√£o da qualidade das respostas foi realizada de forma qualitativa, comparando as respostas geradas com as respostas esperadas. Para uma avalia√ß√£o mais precisa, pode-se fazer uso de m√©tricas quantitativas, como *BLEU*, *ROUGE* ou *Perplexidade*.\n",
        "    * **An√°lise:** O modelo ajustado demonstrou uma melhoria na capacidade de gerar respostas coerentes e relevantes, mas ainda apresenta dificuldades em algumas instru√ß√µes mais complexas.\n",
        "\n",
        "3.  **Agrupamento por Temas:**\n",
        "\n",
        "    * Uma abordagem eficaz seria utilizar um modelo *GPT2 Text-Classification*, por exemplo, para classificar as perguntas em diferentes categorias de temas. O modelo seria ajustado com um dataset de treinamento contendo perguntas e suas respectivas categorias. Em seguida, o modelo seria utilizado para classificar as perguntas dos datasets de treino e teste.\n",
        "    * A utiliza√ß√£o de um modelo GPT2-Classification permite aproveitar o poder dos modelos de linguagem para agrupar as perguntas de forma sem√¢ntica, considerando o significado das palavras e frases.\n",
        "    * **Alternativa:** Outra alternativa seria utilizar t√©cnicas de incorpora√ß√£o de palavras (Word Embeddings) ou modelos de t√≥picos (Topic Modeling) para agrupar as perguntas por temas semelhantes.\n",
        "\n",
        "#### C√≥digo Sugerido para agrupamento por temas (Utilizando Sentence Transformers)\n",
        "\n",
        "```\n",
        "    # Importando depend√™ncias\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # Carregando o modelo Sentence Transformer\n",
        "    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "    # Obtendo as perguntas dos datasets\n",
        "    questions = list(df_train['text']) + list(df_test['text'])\n",
        "\n",
        "    # Gerando os embeddings das perguntas\n",
        "    embeddings = model.encode(questions)\n",
        "\n",
        "    # Agrupando as perguntas usando K-means\n",
        "    num_clusters = 5\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(embeddings)\n",
        "\n",
        "    # Obtendo os r√≥tulos dos clusters\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Imprimindo os resultados\n",
        "    for i in range(num_clusters):\n",
        "        print(f\"Cluster {i}:\")\n",
        "        for j, label in enumerate(labels):\n",
        "            if label == i:\n",
        "                print(questions[j])\n",
        "        print()\n",
        "```"
      ],
      "metadata": {
        "id": "wxIV3xoEcuLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Agrupamento por Temas (Utilizando Sentence Transformers)\n",
        "\n",
        "* O c√≥digo utiliza a biblioteca `sentence_transformers` para gerar embeddings de senten√ßas, que representam o significado das perguntas.\n",
        "* O modelo `distilbert-base-nli-mean-tokens` √© utilizado para gerar os embeddings.\n",
        "* O algoritmo K-means √© utilizado para agrupar as perguntas com base em seus embeddings.\n",
        "* O n√∫mero de clusters (`num_clusters`) pode ser ajustado de acordo com o n√∫mero desejado de grupos de perguntas.\n",
        "* Os r√≥tulos dos clusters s√£o obtidos e utilizados para imprimir as perguntas em cada grupo.\n",
        "\n",
        "#### Melhorias Futuras para agrupar os temas\n",
        "\n",
        "* Explorar diferentes modelos de Sentence Transformers para obter embeddings mais precisos.\n",
        "* Experimentar diferentes algoritmos de agrupamento, como DBSCAN ou agrupamento hier√°rquico.\n",
        "* Utilizar t√©cnicas de redu√ß√£o de dimensionalidade, como PCA ou t-SNE, para visualizar os clusters em um espa√ßo bidimensional ou tridimensional.\n",
        "* Automatizar a sele√ß√£o do n√∫mero ideal de clusters utilizando t√©cnicas como o m√©todo do cotovelo ou a pontua√ß√£o de silhueta.\n",
        "* Avaliar a qualidade dos clusters utilizando m√©tricas como o √≠ndice Davies-Bouldin ou o √≠ndice de silhueta.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FU_4qbi7e5QY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#### Considera√ß√µes Finais\n",
        "\n",
        "Ao longo das Etapas 1, 2 e 3, foi explorado o fine-tuning do modelo GPT2-Small para a gera√ß√£o de texto com base em instru√ß√µes espec√≠ficas. Observamos que o fine-tuning resultou em melhorias na qualidade das respostas geradas pelo modelo, demonstrando a efic√°cia da adapta√ß√£o do modelo aos dados espec√≠ficos do projeto. No entanto, ainda h√° espa√ßo para otimiza√ß√£o e aprimoramento do modelo.\n",
        "\n",
        "#### Melhorias Futuras\n",
        "\n",
        "#### Aprimoramento do Fine-tuning:\n",
        "\n",
        "* **Explora√ß√£o de Hiperpar√¢metros:** Realizar uma busca mais abrangente de hiperpar√¢metros, como taxa de aprendizado, tamanho do lote e n√∫mero de √©pocas, para encontrar a configura√ß√£o ideal para o modelo.\n",
        "* **T√©cnicas de Regulariza√ß√£o:** Implementar t√©cnicas de regulariza√ß√£o, como dropout ou weight decay, para evitar o overfitting e melhorar a generaliza√ß√£o do modelo.\n",
        "* **Modelos Maiores:** Experimentar modelos GPT2 maiores, como GPT2-Medium ou GPT2-Large, para avaliar se eles oferecem melhorias significativas no desempenho. No entanto, √© importante considerar os custos computacionais associados a modelos maiores.\n",
        "* **Fine-tuning Eficiente:** Explorar t√©cnicas de fine-tuning eficientes, como o Parameter-Efficient Fine-Tuning (PEFT), para reduzir o consumo de mem√≥ria e o tempo de treinamento.\n",
        "\n",
        "#### Otimiza√ß√£o da Gera√ß√£o de Texto:\n",
        "\n",
        "* **Ajuste de Par√¢metros de Gera√ß√£o:** Experimentar diferentes valores para os par√¢metros de gera√ß√£o, como `temperature`, `top_k` e `top_p`, para controlar a criatividade e a diversidade das respostas geradas.\n",
        "* **Prompt Engineering:** Aprimorar a formula√ß√£o dos prompts, adicionando instru√ß√µes mais detalhadas ou exemplos, para orientar o modelo na gera√ß√£o de respostas mais precisas e relevantes.\n",
        "* **Modelos de Linguagem Condicionados:** Explorar modelos de linguagem condicionados, como T5 ou BART, que s√£o projetados para tarefas de gera√ß√£o de texto com base em instru√ß√µes ou entradas espec√≠ficas.\n",
        "\n",
        "#### Avalia√ß√£o Abrangente:\n",
        "\n",
        "* **M√©tricas Quantitativas:** Utilizar uma variedade de m√©tricas quantitativas, como BLEU, ROUGE e Perplexidade, para avaliar o desempenho do modelo de forma mais abrangente e objetiva.\n",
        "* **Avalia√ß√£o Humana:** Realizar avalia√ß√µes humanas para avaliar a qualidade das respostas geradas pelo modelo em termos de relev√¢ncia, coer√™ncia e flu√™ncia.\n",
        "* **An√°lise de Erros:** Realizar uma an√°lise detalhada dos erros cometidos pelo modelo para identificar padr√µes e √°reas de melhoria.\n",
        "\n",
        "#### Agrupamento e Categoriza√ß√£o:\n",
        "\n",
        "* **Modelos de Classifica√ß√£o:** Investigar o uso de modelos de classifica√ß√£o de texto, como BERT ou RoBERTa, para categorizar as perguntas por t√≥picos ou temas relevantes.\n",
        "* **Modelos de T√≥picos:** Aplicar modelos de t√≥picos, como LDA ou NMF, para identificar os principais t√≥picos presentes nas perguntas e agrupar perguntas semelhantes.\n",
        "* **Embeddings de Senten√ßas:** Explorar o uso de embeddings de senten√ßas, como Sentence Transformers, para representar as perguntas em um espa√ßo vetorial e agrupar perguntas semanticamente semelhantes.\n",
        "\n",
        "Ao implementar essas melhorias futuras, podemos aprimorar ainda mais o modelo GPT2-Small e obter resultados mais precisos e relevantes na gera√ß√£o de texto com base em instru√ß√µes espec√≠ficas."
      ],
      "metadata": {
        "id": "7bsqGdkygY7F"
      }
    }
  ]
}